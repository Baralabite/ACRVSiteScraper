Authors	Publication Date	Publisher	Description	Citations
Fangyi Zhang, Jürgen Leitner, Michael Milford, Ben Upcroft, Peter Corke	2015	None	Abstract: This paper introduces a machine learning based system for controlling a robotic manipulator with visual perception only. The capability to autonomously learn robot controllers solely from raw-pixel images and without any prior knowledge of configuration is shown for the first time. We build upon the success of recent deep reinforcement learning and develop a system for learning target reaching with a three-joint robot manipulator using external visual observation. A Deep Q Network (DQN) was demonstrated to perform target  ...	24
Josh Weberruss, Lindsay Kleeman, Tom Drummond	2015/12	None	Abstract The ORB (Oriented FAST (Features from Accelerated Segment Test) and Rotated BRIEF (Binary Robust Independent Elementary Features)) feature extractor is the state of the art in wide baseline matching with sparse image features for robotic vision. All previous implementations have employed general-purpose computing hardware, such as CPUs and GPUs. This work seeks to investigate the applicability of special-purpose computing hardware, in the form of Field-Programmable Gate Arrays (FPGAs), to the acceleration of  ...	2
Xiaoqin Wang, Y Ahmet Şekercioğlu, Tom Drummond	2015/4/19	None	Abstract: We consider the self-calibration problem (estimation of location and orientation of multiple camera sensors), in visual sensor networks equipped with RGB-D cameras. We propose two algorithms based on feature matching and relative pose estimation. First one uses Floyd-Warshall algorithm, and can accurately estimate the camera locations. On the other hand, the second algorithm is more scalable than the first one, and can be used in large networks if high accuracy is not an issue. Numerical results demonstrate that both  ...	0
Peng Wang, Chunhua Shen, Anton van den Hengel	2015	None	Abstract Conditional Random Fields (CRFs) are one of the core technologies in computer vision, and have been applied on a wide variety of tasks. Conventional CRFs typically define edges between neighboring image pixels, resulting in a sparse graph over which inference can be performed efficiently. However, these CRFs fail to model more complex priors such as long-range contextual relationships. Fully-connected CRFs have thus been proposed. While there are efficient approximate inference methods for such CRFs, usually they are  ...	11
Niko Sünderhauf, Ben Upcroft, Michael Milford	2015	None	Abstract We propose a novel mathematical formulation for the holistic scene understanding problem and transform it from the discrete into the continuous domain. The problem can then be modeled with a nonlinear continuous factor graph, and the MAP solution is found via least squares optimization. We evaluate our method on the realistic NYU2 dataset.	1
Niko Sünderhauf, Feras Dayoub, Sareh Shirazi, Ben Upcroft, Michael Milford	2015	None	Abstract: After the incredible success of deep learning in the computer vision domain, there has been much interest in applying Convolutional Network (ConvNet) features in robotic fields such as visual navigation and SLAM. Unfortunately, there are fundamental differences and challenges involved. Computer vision datasets are very different in character to robotic camera data, real-time performance is essential, and performance priorities can be different. This paper comprehensively evaluates and compares the utility of three state-of-the-art  ...	61
Niko Sünderhauf, Feras Dayoub, Sean McMahon, Markus Eich, Ben Upcroft, Michael Milford	2015	None	None	0
Andrew Spek, Wai Ho Li, Tom Drummond	2017/7/3	None	Abstract: Estimation of surface curvature from range data is important for a range of tasks in computer vision and robotics, object segmentation, object recognition and robotic grasping estimation. This work presents a fast method of robustly computing accurate metric principal curvature values from noisy point clouds which was implemented on GPU. In contrast to existing readily available solutions which first differentiate the surface to estimate surface normals and then differentiate these to obtain curvature, amplifying noise, our method  ...	3
Hajar Sadeghi Sokeh, Stephen Gould, Jochen Renz	2014	None	Abstract Understanding the activities taking place in a video is a challenging problem in Artificial Intelligence. Complex video sequences contain many activities and involve a multitude of interacting objects. Determining which objects are relevant to a particular activity is the first step in understanding the activity. Indeed many objects in the scene are irrelevant to the main activity taking place. In this work, we consider human-centric activities and look to identify which objects in the scene are involved in the activity. We take an activity- ...	0
James Sergeant, Niko Sünderhauf, Michael Milford, Ben Upcroft	2015	None	Abstract Robot navigation systems are typically engineered to suit certain platforms, sensing suites and environment types. In order to deploy a robot in an environment where its existing navigation system is insufficient, the system must be modified manually, often at significant cost. In this paper we address this problem, proposing a system based on multimodal deep autoencoders that enables a robot to learn how to navigate by observing a dataset of sensor input and motor commands collected while being teleoperated by a human. Low-level  ...	3
Marta Salas, Yasir Latif, Ian D Reid, JMM Montiel	None	None	None	0
Fahimeh Rezazadegan, Sareh Shirazi, Niko Sünderhauf, Michael Milford, Ben Upcroft	2015	None	Deep convolutional network models have dominated recent work in human action recognition as well as image classification. However, these methods are often unduly influenced by the image background, learning and exploiting the presence of cues in typical computer vision datasets. For unbiased robotics applications, the degree of variation and novelty in action backgrounds is far greater than in computer vision datasets. To address this challenge, we propose an “action region proposal” method that, informed by optical flow,  ...	3
Fahimeh Rezazadegan, Sareh Shirazi, Michael Milford, Ben Upcroft	2015	None	Abstract: Object detection is a fundamental task in many computer vision applications, therefore the importance of evaluating the quality of object detection is well acknowledged in this domain. This process gives insight into the capabilities of methods in handling environmental changes. In this paper, a new method for object detection is introduced that combines the Selective Search and EdgeBoxes. We tested these three methods under environmental variations. Our experiments demonstrate the outperformance of the  ...	2
Lukáš Polok, Vincent Lui, Viorela Ila, Tom Drummond, Robert Mahony	2015	None	None	0
Trung T Pham, Ian Reid, Yasir Latif, Stephen Gould	2015	None	Abstract This paper addresses the problem of semantic segmentation of 3D indoor scenes reconstructed from RGB-D images. Traditionally label prediction for 3D points is tackled by employing graphical models that capture scene features and complex relations between different class labels. However, the existing work is restricted to pairwise conditional random fields, which are insufficient when encoding rich scene context. In this work we propose models with higher-order potentials to describe complex relational information from the 3D  ...	4
Edward Pepperell, Peter Corke, Michael Milford	2015/5/27	None	Abstract: Robustness to variations in environmental conditions and camera viewpoint is essential for long-term place recognition, navigation and SLAM. Existing systems typically solve either of these problems, but invariance to both remains a challenge. This paper presents a training-free approach to lateral viewpoint-and condition-invariant, vision-based place recognition. Our successive frame patch-tracking technique infers average scene depth along traverses and automatically rescales views of the same place at different  ...	7
Sakrapee Paisitkriangkrai, Jamie Sherrah, Pranam Janney, Van-Den Hengel	2015	None	Abstract Large amounts of available training data and increasing computing power have led to the recent success of deep convolutional neural networks (CNN) on a large number of applications. In this paper, we propose an effective semantic pixel labelling using CNN features, hand-crafted features and Conditional Random Fields (CRFs). Both CNN and hand-crafted features are applied to dense image patches to produce per-pixel class probabilities. The CRF infers a labelling that smooths regions while respecting the edges present in the  ...	37
Kyel Ok, Dinesh Gamage, Tom Drummond, Frank Dellaert, Nicholas Roy	2015/5/26	None	Abstract: We propose a method of monocular camera-inertial based navigation for computationally limited micro air vehicles (MAVs). Our approach is derived from the recent development of parallel tracking and mapping algorithms, but unlike previous results, we show how the tracking and mapping processes operate using different representations. The separation of representations allows us not only to move the computational load of full map inference to a ground station, but to further reduce the computational cost of on-board  ...	2
Michael Milford, Chunhua Shen, Stephanie Lowry, Niko Suenderhauf, Sareh Shirazi, Guosheng Lin, Fayao Liu, Edward Pepperell, Cesar Lerma, Ben Upcroft, Ian Reid	2015	None	Abstract Vision-based localization on robots and vehicles remains unsolved when extreme appearance change and viewpoint change are present simultaneously. The current state of the art approaches to this challenge either deal with only one of these two problems; for example FAB-MAP (viewpoint invariance) or SeqSLAM (appearance-invariance), or use extensive training within the test environment, an impractical requirement in many application scenarios. In this paper we significantly improve the viewpoint invariance of  ...	12
Sean McMahon, Niko Sünderhauf, Ben Upcroft, Michael Milford	2015/6	None	Abstract Image region proposals are now commonly placed with the current object detection algorithms to provide an efficient technique to locate object regions. The image region proposal algorithm, Edge Boxes [7] is evaluated on the NYU2 dataset [4] and compared with the optimal parameters from a random parameter search. Edge Boxes performance in the cluttered, low resolution images of the NYU2 dataset, commonly encountered in robotics is shown. While comparisons between region proposals has been performed, few have  ...	4
Sean McMahon, Niko Sünderhauf, Michael Milford, Ben Upcroft	2015	None	Abstract This paper introduces TripNet, a robotic vision system that detects trip hazards using raw construction site images. Automated detection of dangers such as trip hazards is difficult. Trip hazards are not entirely defined by an object type, rather trip hazards are affordances typically learnt from time consuming intrusive interaction with an environment and its objects. TripNet performs trip hazard identification using only camera imagery and minimal training with a pre-trained Convolutional Neural Network (CNN) rapidly fine-tuned  ...	1
Andreas Marouchos, Brett Muir, Russ Babcock, Matthew Dunbabin	2015/5/18	None	Abstract: Autonomous underwater vehicles (AUVs) are becoming commonplace in the study of inshore coastal marine habitats. Combined with shipboard systems, scientists are able to make in-situ measurements of water column and benthic properties. In CSIRO, autonomous gliders are used to collect water column data, while surface vessels are used to collect bathymetry information through the use of swath mapping, bottom grabs, and towed video systems. Although these methods have provided good data coverage for coastal and  ...	4
Abed Malti, Adrien Bartoli, Richard Hartley	2015	None	Abstract We cast SfT (Shape-from-Template) as the search of a vector field (X, dX), composed of the pose X and the displacement dX that produces the deformation. We propose the first fully linear least-squares SfT method modeling elastic deformations. It relies on a set of Solid Boundary Constraints SBC to position the template at X in the deformed frame. The displacement is mapped by the stiffness matrix to minimize the amount of force responsible for the deformation. This linear minimization is subjected to the Reprojection  ...	8
Frederic Maire, Luis Mejias Alvarez, Amanda Hodgson	2015/11/30	None	Abstract Aerial surveys conducted using manned or unmanned aircraft with customized camera payloads can generate a large number of images. Manual review of these images to extract data is prohibitive in terms of time and financial resources, thus providing strong incentive to automate this process using computer vision systems. There are potential applications for these automated systems in areas such as surveillance and monitoring, precision agriculture, law enforcement, asset inspection, and wildlife assessment. In this  ...	4
Vincent Lui, Dinesh Gamage, Tom Drummond	2015	None	Abstract This paper proposes a novel method of performing inverse compositional image alignment which elegantly deals with missing data and re-weighting, and does not require the Jacobians and Hessian to be re-computed at every iteration. We show how missing data and re-weighting can be handled through preconditioning. We propose a few preconditioning techniques and analyse how each technique models the effects of missing data and re-weighting for inverse composition. We show through extensive experiments  ...	1
Vincent Lui, Tom Drummond	2015	None	Abstract: This paper presents a monocular visual SLAM system that does not require a globally consistent 3D model. Instead of generating a globally consistent 3D model and localising the camera from the 3D model, the system merely optimises relative pose parameters for pairs of keyframes that overlap on the scene, providing accurate local information at the expense of global consistency. During run-time, the camera is localised using only 2D measurements from nearby keyframes instead of using correspondences  ...	6
Guosheng Lin, Chunhua Shen, Ian Reid, Anton van den Hengel	2015	None	Abstract Deep structured output learning shows great promise in tasks like semantic image segmentation. We proffer a new, efficient deep structured model learning scheme, in which we show how deep Convolutional Neural Networks (CNNs) can be used to directly estimate the messages in message passing inference for structured prediction with Conditional Random Fields CRFs). With such CNN message estimators, we obviate the need to learn or evaluate potential functions for message calculation. This confers significant efficiency for  ...	23
Zhibin Liao, Gustavo Carneiro	2015	None	Abstract: Recently, we have observed the traditional feature representations are being rapidly replaced by the deep learning representations, which produce significantly more accurate classification results when used together with the linear classifiers. However, it is widely known that non-linear classifiers can generally provide more accurate classification but at a higher computational cost involved in their training and testing procedures. In this paper, we propose a new efficient and accurate non-linear hierarchical classification  ...	3
Jürgen Leitner, Donald G Dansereau, Sareh Shirazi, Peter Corke	2015/6	None	Datasets provide open and accessible benchmarks for the refinement of existing algorithms and the testing of new techniques. Notably, recent advances in computer vision, particularly in convolutional and deep neural networks, have been enabled by the availability of appropriate datasets. Though datasets have evolved to contain ever more data, the focus has remained on static and passive information. We propose that in emerging application areas such as augmented reality and robotics, a more active and dynamic approach to  ...	1
Jürgen Leitner	2015/6	None	Scene understanding has been investigated from a mainly visual information point of view. Recently depth has been provided an extra wealth of information, allowing more geometric knowledge to fuse into scene understanding. Yet to form a holistic view, especially in robotic applications, one can create even more data by interacting with the world. In fact humans, when growing up, seem to heavily investigate the world around them by haptic exploration. We show an application of haptic exploration on a humanoid robot in cooperation with a  ...	0
Xu Jia, Efstratios Gavves, Basura Fernando, Tinne Tuytelaars	2015	None	Abstract In this work we focus on the problem of image caption generation. We propose an extension of the long short term memory (LSTM) model, which we coin gLSTM for short. In particular, we add semantic information extracted from the image as extra input to each unit of the LSTM block, with the aim of guiding the model towards solutions that are more tightly coupled to the image content. Additionally, we explore different length normalization strategies for beam search to avoid bias towards short sentences. On various benchmark  ...	25
Adam Jacobson, Zetao Chen, Michael Milford	2015/9/28	None	Abstract: Localization is a critical capability for many autonomous mobile robots. Implicit in all localization and place recognition techniques is the ability to decide whether a place is novel or familiar; the idea of “has this place been visited before?”. To make this decision accurately, localization systems typically require prior calibration or training on datasets from the specific type of operating environment; a requirement that is not practical in many environments or applications. One approach to this problem has been to remove the  ...	1
Adam Jacobson, Zetao Chen, Venkateswara Rao Rallabandi, Michael Milford	None	None	Abstract Most robot navigation systems perform place recognition using a single sensor modality and using one, or at most two heterogeneous map scales. In contrast, mammals likely perform navigation by combining sensing from a wide variety of modalities including vision, auditory, olfaction and tactile senses. Recent robotics research has shown that using multiple homogeneous mapping scales improves localization performance; but this research has used only a single visual sensing modality, missing out on the inherent variation in  ...	0
Viorela Ila, Lukas Polok, Marek Solony, Pavel Smrz, Pavel Zemcik	2015/5/26	None	Abstract: Many estimation problems in robotics rely on efficiently solving nonlinear least squares (NLS). For example, it is well known that the simultaneous localisation and mapping (SLAM) problem can be formulated as a maximum likelihood estimation (MLE) and solved using NLS, yielding a mean state vector. However, for many applications recovering only the mean vector is not enough. Data association, active decisions, next best view, are only few of the applications that require fast state covariance recovery. The problem is not simple  ...	13
Hanxi Li, Yi Li, Fatih Porikli	2014/11/1	None	Abstract Deep neural networks, albeit their great success on feature learning in various computer vision tasks, are usually considered as impractical for online visual tracking because they require very long training time and a large number of training samples. In this work, we present an efficient and very robust online tracking algorithm using a single Convolutional Neural Network (CNN) for learning effective feature representations of the target object over time. Our contributions are multifold: First, we introduce a novel  ...	31
David Hall, Chris McCool, Feras Dayoub, Niko Sunderhauf, Ben Upcroft	2015/1/5	None	Abstract: Fine-grained leaf classification has concentrated on the use of traditional shape and statistical features to classify ideal images. In this paper we evaluate the effectiveness of traditional hand-crafted features and propose the use of deep convolutional neural network (Conv Net) features. We introduce a range of condition variations to explore the robustness of these features, including: translation, scaling, rotation, shading and occlusion. Evaluations on the Flavia dataset demonstrate that in ideal imaging conditions, combining traditional  ...	14
ZongYuan Ge, Christopher McCool, Conrad Sanderson, Peter Corke	2015	None	Abstract Fine-grained categorisation has been a challenging problem due to small inter-class variation, large intra-class variation and low number of training images. We propose a learning system which first clusters visually similar classes and then learns deep convolutional neural network features specific to each subset. Experiments on the popular fine-grained Caltech-UCSD bird dataset show that the proposed method outperforms recent fine-grained categorisation methods under the most difficult setting: no bounding boxes  ...	11
Dinesh Gamage, Tom Drummond	2015/9/28	None	Abstract: Modern approaches to monocular SLAM retain all observations and repeatedly perform bundle adjustment in order to overcome the inconsistency problem that arises in approaches that marginalise out camera positions. Bundle adjustment is inherently an expensive operation and so sparse matrix techniques and double window optimisation on sparsely sampled key-frames are employed to minimize the computational cost.	1
Basura Fernando, Efstratios Gavves, Jose M Oramas, Amir Ghodrati, Tinne Tuytelaars	2015	None	Abstract In this paper we present a method to capture video-wide temporal information for action recognition. We postulate that a function capable of ordering the frames of a video temporally (based on the appearance) captures well the evolution of the appearance within the video. We learn such ranking functions per video via a ranking machine and use the parameters of these as a new video representation. The proposed method is easy to interpret and implement, fast to compute and effective in recognizing a wide variety of  ...	105
Basura Fernando, Efstratios Gavves, Damien Muselet, Tinne Tuytelaars	2015	None	Abstract We present a supervised learning to rank algorithm that effectively orders images by exploiting the structure in image sequences. Most often in the supervised learning to rank literature, ranking is approached either by analysing pairs of images or by optimizing a list-wise surrogate loss function on full sequences. In this work we propose MidRank, which learns from moderately sized sub-sequences instead. These sub-sequences contain useful structural ranking information that leads to better learnability during training and better  ...	7
Masoud Faraki, Mehrtash T Harandi, Fatih Porikli	2015/1/5	None	Abstract: This paper tackles the problem of categorizing materials and textures by exploiting the second order statistics. To this end, we introduce the Extrinsic Vector of Locally Aggregated Descriptors (E-VLAD), a method to combine local and structured descriptors into a unified vector representation where each local descriptor is a Covariance Descriptor (CovD). In doing so, we make use of an accelerated method of obtaining a visual codebook where each atom is itself a CovD. We will then introduce an efficient way of aggregating  ...	5
Markus Eich	None	None	In this paper we describe our approach to RGB-D scene understanding using imprecise a-priori knowledge representation based on fuzzy description logic (FuzzyDL). In contrast to many neural network-based learning approaches, the proposed method uses spatio-semantic knowledge. This is represented by a FuzzyDL knowledge representation using fuzzy concepts, fuzzy rules and fuzzy implications. The advantage of knowledge-based representation is that implicit knowledge is directly extractable by a reasoner, such as  ...	0
Feras Dayoub, Matthew Dunbabin, Peter Corke	2015/9/28	None	Abstract: This paper presents a novel vision-based underwater robotic system for the identification and control of Crown-Of-Thorns starfish (COTS) in coral reef environments. COTS have been identified as one of the most significant threats to Australia's Great Barrier Reef. These starfish literally eat coral, impacting large areas of reef and the marine ecosystem that depends on it. Evidence has suggested that land-based nutrient runoff has accelerated recent outbreaks of COTS requiring extensive use of divers to manually inject  ...	8
Donald G Dansereau, Stefan B Williams, Peter I Corke	2015	None	None	0
Samuel Cunningham-Nelson, Peyman Moghadam, Jonathan Roberts, Alberto Elfes	2015	None	Generating 3D scans of environments and objects is an invaluable tool, which can be used in many industries. A small handheld device known as HeatWave can create a 3D environment map containing visible and thermal information. This paper discusses a system which uses a HeatWave scanner together with a robot mobile manipulator, allowing these scans to be collected without user operation. An algorithm for this system is also presented, obtaining the positions that the robot mobile manipulator must move to, to find the best  ...	1
Zetao Chen, Stephanie Lowry, Adam Jacobson, Zongyuan Ge, Michael Milford	2015/9/28	None	Abstract: The recent focus on performing visual navigation and place recognition in changing environments has resulted in a large number of heterogeneous techniques each utilizing their own learnt or hand crafted visual features. This paper presents a generally applicable method for learning the appropriate distance metric by which to compare feature responses from any of these techniques in order to perform place recognition under changing environmental conditions. We implement an approach which learns to cluster  ...	2
Zetao Chen, Stephanie Lowry, Adam Jacobson, Zongyuan Ge, Michael Milford	2015/9/28	None	Abstract: The recent focus on performing visual navigation and place recognition in changing environments has resulted in a large number of heterogeneous techniques each utilizing their own learnt or hand crafted visual features. This paper presents a generally applicable method for learning the appropriate distance metric by which to compare feature responses from any of these techniques in order to perform place recognition under changing environmental conditions. We implement an approach which learns to cluster  ...	2
William Chamberlain, Tom Drummond, Peter Corke	2015/12	None	Abstract: Robotic vision is limited by line of sight and on-board camera capabilities. Robots can acquire video or images from remote cameras, but processing additional data has a computational burden. This paper applies the Distributed Robotic Vision Service, DRVS, to robot path planning using data outside line-of-sight of the robot. DRVS implements a distributed visual object detection service to distributes the computation to remote camera nodes with processing capabilities. Robots request task-specific object detection from  ...	1
Buyu Liu, Xuming He, Stephen Gould	2015/1/5	None	Abstract: We tackle the problem of semantic segmentation of dynamic scene in video sequences. We propose to incorporate foreground object information into pixel labeling by jointly reasoning semantic labels of super-voxels, object instance tracks and geometric relations between objects. We take an exemplar approach to object modeling by using a small set of object annotations and exploring the temporal consistency of object motion. After generating a set of moving object hypotheses, we design a CRF framework that jointly  ...	9
Alex Bewley, Ben Upcroft	2016	None	Abstract This paper presents visual detection and classification of light vehicles and personnel on a mine site. We capitalise on the rapid advances of ConvNet based object recognition but highlight that a naive black box approach results in a significant number of false positives. In particular, the lack of domain specific training data and the unique landscape in a mine site causes a high rate of errors. We exploit the abundance of background-only images to train a k-means classifier to complement the ConvNet.  ...	3
Thalaiyasingam Ajanthan, Richard Hartley, Mathieu Salzmann, Hongdong Li	2015/6	None	Abstract While widely acknowledged as highly effective in computer vision, multi-label MRFs with non-convex priors are difficult to optimize. To tackle this, we introduce an algorithm that iteratively approximates the original energy with an appropriately weighted surrogate energy that is easier to minimize. Our algorithm guarantees that the original energy decreases at each iteration. In particular, we consider the scenario where the global minimizer of the weighted surrogate energy can be obtained by a multi-label graph cut algorithm, and  ...	5
Khurrum Aftab, Richard Hartley	2015/9/27	None	Abstract: In this paper we propose a method to solve for an L q solution of bundle adjustment, a non-linear parameter estimation problem. Given a set of images of a scene, bundle adjustment simultaneously estimates camera parameters and 3D structure of the scene. Generally, a least squares criterion is minimized by using the Levenberg-Marquardt (LM) method, a non-linear least squares optimization method. It is known that the least squares methods are not robust to outliers, even a single outlier can deviate the solution  ...	2
Khurrum Aftab, Richard Hartley	2015/1/5	None	Abstract: This paper presents a way of using the Iteratively Reweighted Least Squares (IRLS) method to minimize several robust cost functions such as the Huber function, the Cauchy function and others. It is known that IRLS (otherwise known as Weiszfeld) techniques are generally more robust to outliers than the corresponding least squares methods, but the full range of robust M-estimators that are amenable to IRLS has not been investigated. In this paper we address this question and show that IRLS methods can be  ...	11
Zetao Chen, Jones Yuen, Ross Crawford, Jiang Chang, Chengtie Wu, Yin Xiao	2015/8/31	None	Abstract Osteoblast lineage cells are direct effectors of osteogenesis and are, therefore, commonly used to evaluate the in vitro osteogenic capacity of bone substitute materials. This method has served its purposes when testing novel bone biomaterials; however, inconsistent results between in vitro and in vivo studies suggest the mechanisms that govern a material's capacity to mediate osteogenesis are not well understood. The emerging field of osteoimmunology and immunomodulation has informed a paradigm shift in our view of  ...	29
Michael Warren, Luis Mejias, Jonathan Kok, Xilin Yang, Felipe Gonzalez, Ben Upcroft	2015/12	None	Abstract A number of hurdles must be overcome in order to integrate unmanned aircraft into civilian airspace for routine operations. The ability of the aircraft to land safely in an emergency is essential to reduce the risk to people, infrastructure, and aircraft. To date, few field-demonstrated systems have been presented that show online replanning and repeatability from failure to touchdown. This paper presents the development of the guidance, navigation, and control (GNC) component of an automated emergency landing  ...	2
Xiaoqin Wang, Yasar Ahmet Şekercioğlu, Tom Drummond, Enrico Natalizio, Isabelle Fantoni, Vincent Frémont	2016/4	None	Abstract: We propose a new method, called 3-D image warping-based depth video compression (IW-DVC), for fast and efficient compression of depth images captured by mobile RGB-D sensors. The emergence of low-cost RGB-D sensors has created opportunities to find new solutions for a number of computer vision and networked robotics problems, such as 3-D map building, immersive telepresence, or remote sensing. However, efficient transmission and storage of depth data still presents a challenging task to the  ...	0
Xiaoqin Wang, Y Ahmet Şekercioğlu, Tom Drummond	2014/12/26	None	Abstract: We present a new vision based cooperative pose estimation scheme for systems of mobile robots equipped with RGB-D cameras. We first model a multi-robot system as an edge-weighted graph. Then, based on this model, and by using the real-time color and depth data, the robots with shared field-of-views estimate their relative poses in pairwise. The system does not need the existence of a single common view shared by all robots, and it works in 3D scenes without any specific calibration pattern or landmark. The proposed  ...	6
Qinfeng Shi, Mark Reid, Tiberio Caetano, Anton Van den Hengel, Zhenhua Wang	2015/1	None	Abstract: We propose a novel hybrid loss for multiclass and structured prediction problems that is a convex combination of a log loss for Conditional Random Fields (CRFs) and a multiclass hinge loss for Support Vector Machines (SVMs). We provide a sufficient condition for when the hybrid loss is Fisher consistent for classification. This condition depends on a measure of dominance between labels-specifically, the gap between the probabilities of the best label and the second best label. We also prove Fisher consistency is necessary for  ...	5
Inkyu Sa, Stefan Hrabar, Peter Corke	2015	None	Abstract We present a pole inspection system for outdoor environments comprising a high-speed camera on a vertical take-off and landing (VTOL) aerial platform. The pole inspection task requires a vehicle to fly close to a structure while maintaining a fixed stand-off distance from it. Typical GPS errors make GPS-based navigation unsuitable for this task however. When flying outdoors a vehicle is also affected by aerodynamics disturbances such as wind gusts, so the onboard controller must be robust to these disturbances in order to maintain  ...	13
David Ryan, Simon Denman, Sridha Sridharan, Clinton Fookes	2015/1/31	None	Abstract Existing crowd counting algorithms rely on holistic, local or histogram based features to capture crowd properties. Regression is then employed to estimate the crowd size. Insufficient testing across multiple datasets has made it difficult to compare and contrast different methodologies. This paper presents an evaluation across multiple datasets to compare holistic, local and histogram based methods, and to compare various image features and regression models. A K-fold cross validation protocol is followed to evaluate  ...	37
Peer Neubert, Niko Sunderhauf, Peter Protzel	2013/9/25	None	Abstract: Changing environments pose a serious problem to current robotic systems aiming at long term operation. While place recognition systems perform reasonably well in static or low-dynamic environments, severe appearance changes that occur between day and night, between different seasons or different local weather conditions remain a challenge. In this paper we propose to learn to predict the changes in an environment. Our key insight is that the occurring appearance changes are in part systematic, repeatable and therefore  ...	56
Miaomiao Liu, Richard Hartley, Mathieu Salzmann	2015/4/1	None	Abstract This paper tackles the problem of reconstructing the shape of a smooth mirror surface from a single image. In particular, we consider the case where the camera is observing the reflection of a static reference target in the unknown mirror. We first study the reconstruction problem given dense correspondences between 3D points on the reference target and image locations. In such conditions, our differential geometry analysis provides a theoretical proof that the shape of the mirror surface can be uniquely recovered if the pose  ...	28
Stephanie Lowry, Niko Sunderhauf, Paul Newman, John J Leonard, David Cox, Peter Corke, Michael J Milford	2016	None	Abstract: Visual place recognition is a challenging problem due to the vast range of ways in which the appearance of real-world places can vary. In recent years, improvements in visual sensing capabilities, an ever-increasing focus on long-term mobile robot autonomy, and the ability to draw on state-of-the-art research in other disciplines-particularly recognition in computer vision and animal navigation in neuroscience-have all contributed to significant advances in visual place recognition systems. This paper presents a survey of the visual  ...	55
Fayao Liu, Guosheng Lin, Chunhua Shen	2015/10/31	None	Abstract Conditional Random Rields (CRF) have been widely applied in image segmentations. While most studies rely on hand-crafted features, we here propose to exploit a pre-trained large convolutional neural network (CNN) to generate deep features for CRF learning. The deep CNN is trained on the ImageNet dataset and transferred to image segmentations here for constructing potentials of superpixels. Then the CRF parameters are learnt using a structured support vector machine (SSVM). To fully exploit context  ...	36
Xi Li, Chunhua Shen, Anthony Dick, Zhongfei Mark Zhang, Yueting Zhuang	2016/5/1	None	Abstract: In this paper, we propose a visual tracker based on a metric-weighted linear representation of appearance. In order to capture the interdependence of different feature dimensions, we develop two online distance metric learning methods using proximity comparison information and structured output learning. The learned metric is then incorporated into a linear representation of appearance. We show that online distance metric learning significantly improves the robustness of the tracker, especially on those  ...	10
Jingxin Xu, Simon Denman, Sridha Sridharan, Clinton Fookes	2015/6	None	Abstract: Due to the popularity of security cameras in public places, it is of interest to design an intelligent system that can efficiently detect events automatically. This paper proposes a novel algorithm for multiperson event detection. To ensure greater than real-time performance, features are extracted directly from compressed MPEG video. A novel histogram-based feature descriptor that captures the angles between extracted particle trajectories is proposed, which allows us to capture motion patterns for multiperson events  ...	7
Adam Jacobson, Zetao Chen, Michael Milford	2015/1/1	None	Abstract The vast majority of current robot mapping and navigation systems require specific well-characterized sensors that may require human-supervised calibration and are applicable only in one type of environment. Furthermore, if a sensor degrades in performance, either through damage to itself or changes in environmental conditions, the effect on the mapping system is usually catastrophic. In contrast, the natural world presents robust, reasonably well-characterized solutions to these problems. Using simple  ...	8
Hui Li, Chunhua Shen, Anton van den Hengel, Qinfeng Shi	2015/8	None	Abstract: In this paper, we propose an efficient semidefinite programming (SDP) approach to worst case linear discriminant analysis (WLDA). Compared with the traditional LDA, WLDA considers the dimensionality reduction problem from the worst case viewpoint, which is in general more robust for classification. However, the original problem of WLDA is non-convex and difficult to optimize. In this paper, we reformulate the optimization problem of WLDA into a sequence of semidefinite feasibility problems. To efficiently solve the semidefinite  ...	4
Basura Fernando, Tatiana Tommasi, Tinne Tuytelaars	2015/11/1	None	Abstract Domain adaptation aims at adapting the knowledge acquired on a source domain to a new different but related target domain. Several approaches have been proposed for classification tasks in the unsupervised scenario, where no labeled target data are available. Most of the attention has been dedicated to searching a new domain-invariant representation, leaving the definition of the prediction function to a second stage. Here we propose to learn both jointly. Specifically we learn the source subspace that best matches  ...	12
Chamira US Edussooriya, Donald G Dansereau, Len T Bruton, Panajotis Agathoklis	2015/4/15	None	Abstract Five-dimensional (5-D) light field video (LFV)(also known as plenoptic video) is a more powerful form of representing information of dynamic scenes compared to conventional three-dimensional (3-D) video. In this paper, the 5-D spectrum of an object in an LFV is derived for the important practical case of objects moving with constant velocity and at constant depth. In particular, it is shown that the region of support (ROS) of the 5-D spectrum is a skewed 3-D hyperfan in the 5-D frequency domain, with the degree of skew  ...	13
Donald G Dansereau, Oscar Pizarro, Stefan B Williams	2015/2/1	None	We demonstrate that the redundant information in light field imagery allows volumetric focus, an improvement of signal quality that maintains focus over a controllable range of depths. To do this, we derive the frequencydomain region of support of the light field, finding it to be the 4D hyperfan at the intersection of a dual fan and a hypercone, and design a filter with correspondingly shaped passband. Drawing examples from the Stanford Light Field Archive and images captured using a commercially available lenslet-based plenoptic camera, we  ...	29
Anoop Cherian, Vassilios Morellas, Nikos Papanikolopoulos	2015/5	None	Abstract: Symmetric Positive Definite (SPD) matrices emerge as data descriptors in several applications of computer vision such as object tracking, texture recognition, and diffusion tensor imaging. Clustering these data matrices forms an integral part of these applications, for which soft-clustering algorithms (K-Means, expectation maximization, etc.) are generally used. As is well-known, these algorithms need the number of clusters to be specified, which is difficult when the dataset scales. To address this issue, we resort to the classical  ...	3
Zetao Chen, Stephanie Lowry, Adam Jacobson, Michael E Hasselmo, Michael Milford	2015/12/31	None	Abstract Robotic mapping and localization systems typically operate at either one fixed spatial scale, or over two, combining a local metric map and a global topological map. In contrast, recent high profile discoveries in neuroscience have indicated that animals such as rodents navigate the world using multiple parallel maps, with each map encoding the world at a specific spatial scale. While a number of theoretical-only investigations have hypothesized several possible benefits of such a multi-scale mapping system, no one has  ...	6
Jonathan Andersh, Anoop Cherian, Bérénice Mettler, Nikolaos Papanikolopoulos	2015/8/1	None	Abstract Successful operation of a miniature rotorcraft relies on capabilities including automated guidance, trajectory following, and teleoperation; all of which require accurate estimates of the vehicle's body velocities and Euler angles. For larger rotorcraft that operate outdoors, the traditional approach is to combine a highly accurate IMU with GPS measurements. However, for small scale rotorcraft that operate indoors, lower quality MEMS IMUs are used because of limited payload. In indoor applications GPS is usually not  ...	1
Khurrum Aftab, Richard Hartley, Jochen Trumpf	None	None	None	13
J. Leitner	2015/10/6	None	In recent years more and more complex humanoid robots have been developed. On the other hand programming these systems has become more difficult. There is a clear need for such robots to be able to adapt and perform certain tasks autonomously, or even learn by themselves how to act. An important issue to tackle is the closing of the sensorimotor loop. Especially when talking about humanoids the tight integration of perception with actions will allow for improved behaviours, embedding adaptation on the lower-level of the system.	1
