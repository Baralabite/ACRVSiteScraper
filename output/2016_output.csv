Authors	Publication Date	Publisher	Description	Citations
	None	None	None	0
Gao Zhu, Fatih Porikli, Hongdong Li	2016/10/5	None	Abstract: Conventional tracking-by-detection approaches for visual object tracking often assume that the task at hand is a binary foreground-versus-background classification problem where the background is a single, generic, and all-inclusive class. In contrast, here we argue that the background appearance for the most part possesses a more complicated structure that will benefit from further partitioning into multiple contextual clusters. Our observation is that, although the background class is contemplated to contain a vast intra- ...	0
	None	None	None	0
Jingxin Xu, Clinton Fookes, Sridha Sridharan	2016/12/6	None	Abstract: Signal-based Surveillance systems such as Closed Circuits Televisions (CCTV) have been widely installed in public places. Those systems are normally used to find the events with security interest, and play a significant role in public safety. Though such systems are still heavily reliant on human labour to monitor the captured information, there have been a number of automatic techniques proposed to analysing the data. This article provides an overview of automatic surveillance event detection techniques. Despite it's  ...	0
Zifeng Wu, Chunhua Shen, Anton van den Hengel	2016/11/30	None	Abstract: The trend towards increasingly deep neural networks has been driven by a general observation that increasing depth increases the performance of a network. Recently, however, evidence has been amassing that simply increasing depth may not be the best way to increase performance, particularly given other limitations. Investigations into deep residual networks have also suggested that they may not in fact be operating as a single deep network, but rather as an ensemble of many relatively shallow networks. We  ...	14
Qi Wu, Chunhua Shen, Peng Wang, Anthony Dick, Anton van den Hengel	2017	None	Abstract: Much of the recent progress in Vision-to-Language problems has been achieved through a combination of Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs). This approach does not explicitly represent high-level semantic concepts, but rather seeks to progress directly from image features to text. In this paper we first propose a method of incorporating high-level concepts into the successful CNN-RNN approach, and show that it achieves a significant improvement on the state-of-the-art in  ...	12
Peng Wang, Qi Wu, Chunhua Shen, Anton van den Hengel	2017	None	Abstract: One of the most intriguing features of the Visual Question Answering (VQA) challenge is the unpredictability of the questions. Extracting the information required to answer them demands a variety of image operations from detection and counting, to segmentation and reconstruction. To train a method to perform even one of these operations accurately from {image, question, answer} tuples would be challenging, but to aim to achieve them all with a limited set of such training data seems ambitious at best. We  ...	1
Peng Wang, Lingqiao Liu, Chunhua Shen, Zi Huang, Anton van den Hengel, Heng Tao Shen	2016	None	Abstract This paper studies the challenging problem of identifying unusual instances of known objects in images within an" open world" setting. That is, we aim to find objects that are members of a known class, but which are not typical of that class. Thus the" unusual object" should be distinguished from both the" regular object" and the" other objects". Such unusual objects may be of interest in many applications such as surveillance or quality control. We propose to identify unusual objects by inspecting the distribution of object  ...	2
Dorian Tsai, Donald G Dansereau, Steve Martin, Peter Corke	2016/12/16	None	Abstract: This paper proposes the design of a custom mirror-based light field camera adapter that is cheap, simple in construction, and accessible. Mirrors of different shape and orientation reflect the scene into an upwards-facing camera to create an array of virtual cameras with overlapping field of view at specified depths, and deliver video frame rate light fields. We describe the design, construction, decoding and calibration processes of our mirror-based light field camera adapter in preparation for an open-source release to  ...	1
Damien Teney, Lingqiao Liu, Anton van den Hengel	2016/9/19	None	Abstract: This paper proposes to improve visual question answering (VQA) with structured representations of both scene contents and questions. A key challenge in VQA is to require joint reasoning over the visual and text domains. The predominant CNN/LSTM-based approach to VQA is limited by monolithic vector representations that largely ignore structure in the scene and in the form of the question. CNN feature vectors cannot effectively capture situations as simple as multiple object instances, and LSTMs process questions as series  ...	4
Niko Sünderhauf, Trung T Pham, Yasir Latif, Michael Milford, Ian Reid	2016/9/26	None	Abstract: For intelligent robots to interact in deeply meaningful ways with their environment, they must understand both the geometric and semantic properties of the scene surrounding them. The majority of research to date has addressed these mapping challenges separately, focusing on either geometric or semantic mapping. In this paper we address the problem of building environmental maps that include both semantically meaningful, object-level entities and point-or mesh-based geometrical representations. We simultaneously build geometric  ...	1
Seyed Hamid Rezatofighi, Anton Milan, Ehsan Abbasnejad, Anthony Dick, Ian Reid	2016/11/28	None	Abstract: This paper addresses the task of set prediction using deep learning. This is important because the output of many computer vision tasks, including image tagging and object detection, are naturally expressed as sets of entities rather than vectors. As opposed to a vector, the size of a set is not fixed in advance, and it is invariant to the ordering of entities within it. We define a likelihood for a set distribution and learn its parameters using a deep neural network. We also derive a loss for predicting a discrete distribution  ...	0
Pulak Purkait, Tat-Jun Chin, Alireza Sadri, David Suter	2016/10/4	None	Abstract: The extension of conventional clustering to hypergraph clustering, which involves higher order similarities instead of pairwise similarities, is increasingly gaining attention in computer vision. This is due to the fact that many clustering problems require an affinity measure that must involve a subset of data of size more than two. In the context of hypergraph clustering, the calculation of such higher order similarities on data subsets gives rise to hyperedges. Almost all previous work on hypergraph clustering in computer vision,  ...	14
Anton Milan, Laura Leal-Taixé, Ian Reid, Stefan Roth, Konrad Schindler	2016/3/2	None	Abstract: Standardized benchmarks are crucial for the majority of computer vision applications. Although leaderboards and ranking tables should not be over-claimed, benchmarks often provide the most objective measure of performance and are therefore important guides for reseach. Recently, a new benchmark for Multiple Object Tracking, MOTChallenge, was launched with the goal of collecting existing and new data and creating a framework for the standardized evaluation of multiple object tracking methods. The first  ...	44
	None	None	None	0
Guosheng Lin, Chunhua Shen, Anton van den Hengel, Ian Reid	2017	None	Abstract: We propose an approach for exploiting contextual information in semantic image segmentation, and particularly investigate the use of patch-patch context and patch-background context in deep CNNs. We formulate deep structured models by combining CNNs and Conditional Random Fields (CRFs) for learning the patch-patch context between image regions. Specifically, we formulate CNN-based pairwise potential functions to capture semantic correlations between neighboring patches. Efficient piecewise training of the  ...	13
Guosheng Lin, Anton Milan, Chunhua Shen, Ian Reid	2017	None	None	14
Yao Li, Guosheng Lin, Bohan Zhuang, Lingqiao Liu, Chunhua Shen, Anton van den Hengel	2017	None	Abstract: Recognizing the identities of people in everyday photos is still a very challenging problem for machine vision, due to non-frontal faces, changes in clothing, location, lighting and similar. Recent studies have shown that rich relational information between people in the same photo can help in recognizing their identities. In this work, we propose to model the relational information between people as a sequence prediction task. At the core of our work is a novel recurrent network architecture, in which relational information between  ...	1
Jürgen Leitner, Adam W Tow, Jake E Dean, Niko Suenderhauf, Joseph W Durham, Matthew Cooper, Markus Eich, Christopher Lehnert, Ruben Mangels, Christopher McCool, Peter Kujala, Lachlan Nicholson, Trung Pham, James Sergeant, Fangyi Zhang, Ben Upcroft, Peter Corke	2016/9/17	None	Abstract: Robotic challenges like the Amazon Picking Challenge (APC) or the DARPA Challenges are an established and important way to drive scientific progress as they make research comparable on a well-defined benchmark with equal test conditions for all participants. However, such challenge events occur only occasionally, are limited to a small number of contestants, and the test conditions are very difficult to replicate after the main event. We present a new physical benchmark challenge for robotic picking. The ACRV  ...	1
Mehrtash Harandi, Mathieu Salzmann, Richard Hartley	2017/1/18	None	Abstract: Representing images and videos with Symmetric Positive Definite (SPD) matrices, and considering the Riemannian geometry of the resulting space, has been shown to yield high discriminative power in many visual recognition tasks. Unfortunately, computation on the Riemannian manifold of SPD matrices–especially of high-dimensional ones–comes at a high cost that limits the applicability of existing techniques. In this paper, we introduce algorithms able to handle high-dimensional SPD matrices by constructing a lower- ...	6
Mehrtash Harandi, Basura Fernando	2016/11/17	None	Abstract: This paper introduces an extension of the backpropagation algorithm that enables us to have layers with constrained weights in a deep network. In particular, we make use of the Riemannian geometry and optimization techniques on matrix manifolds to step outside of normal practice in training deep networks, equipping the network with structures such as orthogonality or positive definiteness. Based on our development, we make another contribution by introducing the Stiefel layer, a layer with orthogonal weights. Among  ...	3
Stephen Gould, Basura Fernando, Anoop Cherian, Peter Anderson, Rodrigo Santa Cruz, Edison Guo	2016/7/19	None	Abstract: Some recent works in machine learning and computer vision involve the solution of a bi-level optimization problem. Here the solution of a parameterized lower-level problem binds variables that appear in the objective of an upper-level problem. The lower-level problem typically appears as an argmin or argmax optimization problem. Many techniques have been proposed to solve bi-level optimization problems, including gradient descent, which is popular with current end-to-end learning approaches. In this technical report we  ...	5
Basura Fernando, Sareh Shirazi, Stephen Gould	2016/12/2	None	Abstract: We propose a new task of unsupervised action detection by action matching. Given two long videos, the objective is to temporally detect all pairs of matching video segments. A pair of video segments are matched if they share the same human action. The task is category independent---it does not matter what action is being performed---and no supervision is used to discover such video segments. Unsupervised action detection by action matching allows us to align videos in a meaningful manner. As such, it can be used  ...	0
Basura Fernando, Efstratios Gavves, José Oramas, Amir Ghodrati, Tinne Tuytelaars	2017/4/1	None	Abstract: We propose a function-based temporal pooling method that captures the latent structure of the video sequence data-eg, how frame-level features evolve over time in a video. We show how the parameters of a function that has been fit to the video data can serve as a robust new video representation. As a specific example, we learn a pooling function via ranking machines. By learning to rank the frame-level features of a video in chronological order, we obtain a new representation that captures the video-wide  ...	30
Basura Fernando, Hakan Bilen, Efstratios Gavves, Stephen Gould	2016/11/21	None	Abstract: We propose a new self-supervised CNN pre-training technique based on a novel auxiliary task called" odd-one-out learning". In this task, the machine is asked to identify the unrelated or odd element from a set of otherwise related elements. We apply this technique to self-supervised video representation learning where we sample subsequences from videos and ask the network to learn to predict the odd video subsequence. The odd video subsequence is sampled such that it has wrong temporal order of frames while the even  ...	5
Markus Eich, Sareh Shirazi, Gordon Wyeth	2016/10/18	None	Abstract: To have a robot actively supporting a human during a collaborative task, it is crucial that robots are able to identify the current action in order to predict the next one. Common approaches make use of high-level knowledge, such as object affordances, semantics or understanding of actions in terms of pre-and post-conditions. These approaches often require hand-coded a priori knowledge, time-and resource-intensive or supervised learning techniques. We propose to reframe this problem as an appearance-based place  ...	0
	None	None	None	0
Yuanzhouhan Cao, Chunhua Shen, Heng Tao Shen	2016/10/6	None	Abstract: Augmenting RGB data with measured depth has been shown to improve the performance of a range of tasks in computer vision, including object detection and semantic segmentation. Although depth sensors such as the Microsoft Kinect have facilitated easy acquisition of such depth information, the vast majority of images used in vision tasks do not contain depth information. In this paper, we show that augmenting RGB images with estimated depth can also improve the accuracy of both object detection and semantic  ...	0
Moses Bangura, Marco Melega, Roberto Naldi, Robert Mahony	2016/1/5	None	Abstract: In this report, we present the theory on aerodynamics of quadrotors using the well established momentum and blade element theories. From a robotics perspective, the theoretical development of the models for thrust and horizontal forces and torque (therefore power) are carried out in the body fixed frame of the quadrotor. Using momentum theory, we propose and model the existence of a horizontal force along with its associated power. Given the limitations associated with momentum theory and the inadequacy of the theory  ...	5
Peter Anderson, Basura Fernando, Mark Johnson, Stephen Gould	2017	None	Abstract: Existing image captioning models do not generalize well to out-of-domain images containing novel scenes or objects. This limitation severely hinders the use of these models in real world applications dealing with images in the wild. We address this problem using a flexible approach that enables existing deep captioning architectures to take advantage of image taggers at test time, without re-training. Our method uses constrained beam search to force the inclusion of selected tag words in the output, and fixed, pretrained word  ...	1
Mohammad Sadegh Aliakbarian, Fatemehsadat Saleh, Basura Fernando, Mathieu Salzmann, Lars Petersson, Lars Andersson	2016/11/17	None	Abstract: Action recognition and anticipation are key to the success of many computer vision applications. Existing methods can roughly be grouped into those that extract global, context-aware representations of the entire image or sequence, and those that aim at focusing on the regions where the action occurs. While the former may suffer from the fact that context is not always reliable, the latter completely ignore this source of information, which can nonetheless be helpful in many situations. In this paper, we aim at making the best of both  ...	1
Juan David Adarve, Robert Mahony	2017/4	None	Abstract: This letter introduces the “spherepix” data structure for efficient implementation of low-level image processing operations on spherical images. Efficient implementation of low-level image processing depends heavily on separability of the convolution kernels that form the fundamental building blocks of most algorithms. Due to the curvature of the sphere, it is not possible to place an orthogonal grid pixelation globally on its surface, making direct application of classical separable kernel convolutions impossible. In the spherepix data  ...	0
Ehsan Abbasnejad, Anthony Dick, Anton van den Hengel	2016/11/23	None	Abstract: This paper presents an infinite variational autoencoder (VAE) whose capacity adapts to suit the input data. This is achieved using a mixture model where the mixing coefficients are modeled by a Dirichlet process, allowing us to integrate over the coefficients when performing inference. Critically, this then allows us to automatically vary the number of autoencoders in the mixture based on the data. Experiments show the flexibility of our method, particularly for semi-supervised learning, where only a small number of training  ...	1
Bohan Zhuang, Guosheng Lin, Chunhua Shen, Ian Reid	2016	None	Abstract In this paper, we aim to learn a mapping (or embedding) from images to a compact binary space in which Hamming distances correspond to a ranking measure for the image retrieval task. We make use of a triplet loss because this has been shown to be most effective for ranking problems. How-ever, training in previous works can be prohibitively expensive due to the fact that optimization is directly performed on the triplet space, where the number of possible triplets for training is cubic in the number of training examples. To  ...	11
Gao Zhu, Fatih Porikli, Hongdong Li	2016	None	Abstract Object tracking has been widely used yet still a challenge for surveillance as the drastic size change, deformation and occlusion present. While it is hard to design such an online classifier that adapts to all those changes, in this paper, we employ an object proposal network to generate a small set of bounding box candidates. In a new frame, only these" object-like" candidates are necessary for the classifier to test, which excludes spurious false positives. We also use them to update and improve the discriminative  ...	6
Gao Zhu, Fatih Porikli, Hongdong Li	2016	None	Abstract Most tracking-by-detection methods employ a local search window around the predicted object location in the current frame assuming the previous location is accurate, the trajectory is smooth, and the computational capacity permits a search radius that can accommodate the maximum speed yet small enough to reduce mismatches. These, however, may not be valid always, in particular for fast and irregularly moving objects. Here, we present an object tracker that is not limited to a local search window and has ability to  ...	15
Yi Zhou, Laurent Kneip, Hongdong Li	2016/10/9	None	Abstract: Low-drift rotation estimation is a crucial part of any accurate odometry system. In this paper, we focus on the problem of 3D rotation estimation with dense depth sensors in environments that consist of piece-wise planar structures, such as corridors and office rooms. An efficient mean-shift paradigm is developed to extract and track planar modes in the surface normal vector distribution on the unit sphere. Robust and piece-wise drift-free behavior is achieved by registering the bundle of planar modes from the current frame  ...	0
Yi Zhou, Laurent Kneip, Hongdong Li	2015/11/23	None	Abstract: Determining the fundamental matrix from a collection of inter-frame homographies (more than two) is a classical problem. The compatibility relationship between the fundamental matrix and any of the ideally consistent homographies can be used to compute the fundamental matrix. Using the direct linear transformation (DLT), the compatibility equation can be translated into a least squares problem and can be easily solved via SVD decomposition. However, this solution is extremely susceptible to noise and motion  ...	0
Hao Zhou, Jose M Alvarez, Fatih Porikli	2016/10/8	None	Abstract To attain a favorable performance on large-scale datasets, convolutional neural networks (CNNs) are usually designed to have very high capacity involving millions of parameters. In this work, we aim at optimizing the number of neurons in a network, thus the number of parameters. We show that, by incorporating sparse constraints into the objective function, it is possible to decimate the number of neurons during the training stage. As a result, the number of parameters and the memory footprint of the neural network are also  ...	6
Lei Zhang, Wei Wei, Yanning Zhang, Chunhua Shen, Anton van den Hengel, Qinfeng Shi	2016/10/8	None	Abstract Hyperspectral images (HSIs) can facilitate extensive computer vision applications with the extra spectra information. However, HSIs often suffer from noise corruption during the practical imaging procedure. Though it has been testified that intrinsic correlation across spectrum and spatial similarity (ie, local similarity in locally smooth areas and non-local similarity among recurrent patterns) in HSIs are useful for denoising, how to fully exploit them together to obtain a good denoising model is seldom studied. In this study, we  ...	0
Junjie Zhang, Jian Zhang, Jianfeng Lu, Chunhua Shen, Kate Curr, Robin Phua, Richard Neville, Elise Edmonds	2016/11/30	None	Abstract: This paper introduces a dataset of historical images created by the State Library of New South Wales and the University of Technology Sydney (UTS). The dataset has a total of 29713 images with 119 unique labels. Each image contains multiple labels. We use a CNN-based framework to explore the feasibility of our dataset in image multi-labeling and retrieval research, and extract semantic level image features for future research use. The experiment results illustrate that effective deep learning models can be trained on our dataset. We  ...	0
Rui Zeng, Ruan Lakemond, Simon Denman, Sridha Sridharan, Clinton Fookes, Stuart Morgan	2016/11/30	None	Abstract: When processing video, it is normally assumed that cameras are vertically oriented such that people appear upright, which helps simplify subsequent processing such as person detection. In real situations, due to the need to provide maximum coverage of the viewing space, cameras are usually placed with arbitrary orientations so the apparent vertical axis of the videos captured may not correspond to the true vertical direction of the captured scene. To rectify this situation, we propose a classification-based system, which  ...	0
Xin Yu, Fatih Porikli	2016/10/8	None	Abstract Conventional face super-resolution methods, also known as face hallucination, are limited up to 2\! ∼\! 4 * 2∼ 4× scaling factors where 4 ∼ 16 4∼ 16 additional pixels are estimated for each given pixel. Besides, they become very fragile when the input low-resolution image size is too small that only little information is available in the input image. To address these shortcomings, we present a discriminative generative network that can ultra-resolve a very low resolution face image of size 16 * 16 16× 16 pixels to its 8 * 8×  ...	9
Anoop Cherian, Suvrit Sra	2017/5/20	None	Abstract: Data encoded as symmetric positive definite (SPD) matrices frequently arise in many areas of computer vision and machine learning. While these matrices form an open subset of the Euclidean space of symmetric matrices, viewing them through the lens of non-Euclidean Riemannian (Riem) geometry often turns out to be better suited in capturing several desirable data properties. Inspired by the great success of dictionary learning and sparse coding (DLSC) for vector-valued data, our goal in this paper is to represent data in  ...	11
	None	None	None	0
Guobao Xiao, Hanzi Wang, Yan Yan, David Suter	2016/10/8	None	Abstract This paper proposes a two-view deterministic geometric model fitting method, termed Superpixel-based Deterministic Fitting (SDF), for multiple-structure data. SDF starts from superpixel segmentation, which effectively captures prior information of feature appearances. The feature appearances are beneficial to reduce the computational complexity for deterministic fitting methods. SDF also includes two original elements, ie, a deterministic sampling algorithm and a novel model selection algorithm. The two  ...	1
Qi Wu, Peng Wang, Chunhua Shen, Anton van den Hengel, Anthony Dick	2016	None	Abstract We propose a method for visual question answering which combines an internal representation of the content of an image with information extracted from a general knowledge base to answer a broad range of image-based questions. This allows more complex questions to be answered using the predominant neural network-based approach than has previously been possible. It particularly allows questions to be asked about the contents of an image, even when the image itself does not contain the whole answer. The  ...	51
Qi Wu, Chunhua Shen, Lingqiao Liu, Anthony Dick, Anton van den Hengel	2016	None	Abstract Much recent progress in Vision-to-Language (V2L) problems has been achieved through a combination of Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs). This approach does not explicitly represent high-level semantic concepts, but rather seeks to progress directly from image features to text. In this paper we investigate whether this direct approach succeeds due to, or despite, the fact that it avoids the explicit representation of high-level information. We propose a method of incorporating high-level  ...	44
Liao Wu, Keyu Wu, Hongliang Ren	2016/10/9	None	Abstract: Comprised of multiple telescoptic precurved tubes that can independently rotate and translate, concentric tube robots (CTRs) are favorable in minimally invasive surgeries thanks to their small size and considerable dexterity along with curvilinear accessibility. However, there is a lack of investigation on improvement of the surgeons' perception which in turn can be used to guide the telemanipulation. In this work, we proposed an eye-in-hand configuration for the concentric tube robot by adding an endoscope to the tip of the inner  ...	1
Xiaoqin Wang, Y Ahmet Şekercioğlu, Tom Drummond, Enrico Natalizio, Isabelle Fantoni, Vincent Frémont	2016/9/19	None	Abstract: We present a scheme for multi-sensor data fusion applications, called Relative Pose based Redundancy Removal (RPRR), that efficiently enhances the wireless channel utilization in bandwidth-constrained operational scenarios for RGB-D camera equipped visual sensor networks. Pairs of nodes cooperatively determine their own relative pose, and by using this knowledge they identify the correlated data related to the common regions of the captured color and depth images. Then, they only transmit the non-redundant  ...	0
Fernando Vanegas, Duncan Campbell, Markus Eich, Felipe Gonzalez	2016/10/9	None	Abstract: In this paper we describe and flight test a novel system architecture for low cost muti-rotor unmanned aerial vehicles (UAVs) for searching, tracking and following a ground target. The UAV uses only on-board sensors for localisation within a GPS-denied space with obstacles. This mission is formulated as a Partially Observable Markov Decision Process (POMDP) and uses a modular framework that runs on the Robotic Operating System (ROS). This system computes a policy for executing actions instead of way-points to navigate and  ...	0
Ben Talbot, Obadiah Lam, Ruth Schulz, Feras Dayoub, Ben Upcroft, Gordon Wyeth	2016/5/16	None	Abstract: This paper shows that by using only symbolic language phrases, a mobile robot can purposefully navigate to specified rooms in previously unexplored environments. The robot intelligently organises a symbolic language description of the unseen environment and “imagines” a representative map, called the abstract map. The abstract map is an internal representation of the topological structure and spatial layout of symbolically defined locations. To perform goal-directed exploration, the abstract map creates a high-level  ...	0
Niko Sünderhauf, Feras Dayoub, Sean McMahon, Ben Talbot, Ruth Schulz, Peter Corke, Gordon Wyeth, Ben Upcroft, Michael Milford	2016	None	Abstract: In this paper we focus on the challenging problem of place categorization and semantic mapping on a robot without environment-specific training. Motivated by their ongoing success in various visual recognition tasks, we build our system upon a state-of-the-art convolutional network. We overcome its closed-set limitations by complementing the network with a series of one-vs-all classifiers that can learn to recognize new semantic classes online. Prior domain knowledge is incorporated by embedding the classification  ...	7
Gavin Suddrey, Markus Eich, Frederic Maire, Jonathan Roberts	2016/12/5	None	Abstract Hierarchical tasks learnt from situation specific explanations are typically limited in how well they generalise to situations beyond the explanation provided. To address this we present an approach to learning functional argument mappings for enabling task generalisation regardless of explanation specificity. These functional argument mappings allow subtasks within a hierarchical task to utilise both arguments provided to the parent task, as well as domain knowledge, to generalise to novel situations. We validate this  ...	0
Mario Strydom, Anjali Jaiprakash, Ross Crawford, Thierry Peynot, Jonathan M Roberts	2016/12/6	None	This paper evaluates the ability of visual segmentation algorithms to detect the space inside the knee joint; as recorded by a surgeon's arthroscopic video camera, during minimally invasive surgery. We call this space the 'instrument gap'. Video data was obtained during cadaver experiments, and three segmentation algorithms were tested and compared against a thousand marked-up frames of the instrument gap, prepared by an expert surgeon. Algorithms tested include adaptive thresholding, watershed, and level set active contours.  ...	0
Thomas Stone, Dario Differt, Michael Milford, Barbara Webb	2016/5/16	None	Abstract: Place recognition is a key capability for navigating robots. While significant advances have been achieved on large, stable platforms such as robot cars, achieving robust performance on rapidly manoeuvring platforms in outdoor natural conditions remains a challenge, with few systems able to deal with both variable conditions and large tilt variations caused by rough terrain. Taking inspiration from biology, we propose a novel combination of sensory modality and image processing to obtain a significant  ...	3
John Skinner, Sourav Garg, Niko Sünderhauf, Peter Corke, Ben Upcroft, Michael Milford	2016/10/9	None	Abstract: Robotic vision, unlike computer vision, typically involves processing a stream of images from a camera with time varying pose operating in an environment with time varying lighting conditions and moving objects. Repeating robotic vision experiments under identical conditions is often impossible, making it difficult to compare different algorithms. For machine learning applications a critical bottleneck is the limited amount of real world image data that can be captured and labelled for both training and testing purposes. In this paper  ...	1
Sareh Shirazi, Conrad Sanderson, Chris McCool, Mehrtash T Harandi	2015/11/23	None	Abstract: We propose an adaptive tracking algorithm where the object is modelled as a continuously updated bag of affine subspaces, with each subspace constructed from the object's appearance over several consecutive frames. In contrast to linear subspaces, affine subspaces explicitly model the origin of subspaces. Furthermore, instead of using a brittle point-to-subspace distance during the search for the object in a new frame, we propose to use a subspace-to-subspace distance by representing candidate image areas also as  ...	3
Fatemehsadat Saleh, Mohammad Sadegh Ali Akbarian, Mathieu Salzmann, Lars Petersson, Stephen Gould, Jose M Alvarez	2016/10/8	None	Abstract Pixel-level annotations are expensive and time consuming to obtain. Hence, weak supervision using only image tags could have a significant impact in semantic segmentation. Recently, CNN-based methods have proposed to fine-tune pre-trained networks using image tags. Without additional information, this leads to poor localization accuracy. This problem, however, was alleviated by making use of objectness priors to generate foreground/background masks. Unfortunately these priors either require training pixel- ...	14
Seyed Hamid Rezatofighi, Anton Milan, Zhen Zhang, Qinfeng Shi, Anthony Dick, Ian Reid	2016	None	None	4
Ruizhi Qiao, Lingqiao Liu, Chunhua Shen, Anton van den Hengel	2016/4/5	None	Abstract Classifying a visual concept merely from its associated online textual source, such as a Wikipedia article, is an attractive research topic in zero-shot learning because it alleviates the burden of manually collecting semantic attributes. Several recent works have pursued this approach by exploring various ways of connecting the visual and text domains. This paper revisits this idea by stepping further to consider one important factor: the textual representation is usually too noisy for the zero-shot learning application. This  ...	14
Abigyat B Prasai, Anjali Jaiprakash, Ajay K Pandey, Ross Crawford, Jonathan Roberts, Liao Wu	2016/11/13	None	Abstract: Conventional concentric tube robots (CTRs) have low dexterity at the tip, which does not fit the requirements of complicated operations in minimally invasive surgery. A 2mm diameter cable-driven micro end effector is designed and fabricated for CTRs to increase dexterity in confined spaces. The end-effector is made by a simple fabrication procedure and is a combination of readily available materials such as polyolefin tube, acrylic and steel strings. If mass produced, the end effector has the potential to be made into a  ...	1
Lukas Polok, Viorela Ila, Pavel Smrz	2016/8/29	None	Abstract: 3D reconstruction has a wide variety of applications in computer graphics, robotics or digital cinema production, among others. With the rapid increase in computing power, it has become more feasible for the reconstruction algorithms to run online, even on mobile devices. Maximum likelihood estimation (MLE) is the adopted technique to deal with the sensor uncertainty. Most of the existing 3D reconstruction frameworks only recover the mean of the reconstructed geometry. Recovering also the variance is highly computationally  ...	0
Trung T Pham, Seyed Hamid Rezatofighi, Ian Reid, Tat-Jun Chin	2016	None	Abstract We tackle the problem of large-scale object detection in images, where the number of objects can be arbitrarily large, and can exhibit significant overlap/occlusion. A successful approach to modelling the large-scale nature of this problem has been via point process density functions which jointly encode object qualities and spatial interactions. But the corresponding optimisation problem is typically difficult or intractable, and many of the best current methods rely on Monte Carlo Markov Chain (MCMC) simulation, which converges  ...	6
Trung T Pham, Markus Eich, Ian Reid, Gordon Wyeth	2016/10/9	None	Abstract: Modern SLAM systems with a depth sensor are able to reliably reconstruct dense 3D geometric maps of indoor scenes. Representing these maps in terms of meaningful entities is a step towards building semantic maps for autonomous robots. One approach is to segment the 3D maps into semantic objects using Conditional Random Fields (CRF), which requires large 3D ground truth datasets to train the classification model. Additionally, the CRF inference is often computationally expensive. In this paper, we present an  ...	2
Kien Nguyen, Clinton Fookes, Sridha Sridharan	2016/9/25	None	Abstract: Deep convolutional neural networks (DCNNs) have been employed in many computer vision tasks with great success due to their robustness in feature learning. One of the advantages of DCNNs is their representation robustness to object locations, which is useful for object recognition tasks. However, this also discards spatial information, which is useful when dealing with topological information of the image (eg scene labeling, face recognition). In this paper, we propose a deeper and wider network architecture to tackle  ...	0
Chuong V Nguyen, Jurgen Fripp, David R Lovell, Robert Furbank, Peter Kuffner, Helen Daily, Xavier Sirault	2016/11/30	None	Abstract: Thin leaves, fine stems, self-occlusion, non-rigid and slowly changing structures make plants difficult for three-dimensional (3D) scanning and reconstruction-two critical steps in automated visual phenotyping. Many current solutions such as laser scanning, structured light, and multiview stereo can struggle to acquire usable 3D models because of limitations in scanning resolution and calibration accuracy. In response, we have developed a fast, low-cost, 3D scanning platform to image plants on a rotating stage with two tilting  ...	0
	None	None	None	0
Shahin Rahmatollahi Namin, Jose M Alvarez, Laurent Kneip, Lars Petersson	2016/9/25	None	Abstract: In the last years, the increasing availability of annotated data has facilitated the great success of supervised learning in real-world applications such as semantic labeling. However, the vast majority of data is nowadays unlabeled or partially annotated. In this paper, we develop an Expected Marginal Latent Structural SVM (EM-LSSVM) framework for performing structured learning in the presence of weakly (partially) annotated data by incorporating the uncertainty of the unobserved data as marginals. Experimental results  ...	1
James Mount, Michael Milford	2016/5/16	None	Abstract: Domestic service robots such as lawn mowing and vacuum cleaning robots are the most numerous consumer robots in existence today. While early versions employed random exploration, recent systems fielded by most of the major manufacturers have utilized range-based and visual sensors and user-placed beacons to enable robots to map and localize. However, active range and visual sensing solutions have the disadvantages of being intrusive, expensive, or only providing a 1D scan of the environment, while the  ...	2
Christopher McCool, Inkyu Sa, Feras Dayoub, Christopher Lehnert, Tristan Perez, Ben Upcroft	2016/5/16	None	Abstract: This paper presents a novel crop detection system applied to the challenging task of field sweet pepper (capsicum) detection. The field-grown sweet pepper crop presents several challenges for robotic systems such as the high degree of occlusion and the fact that the crop can have a similar colour to the background (green on green). To overcome these issues, we propose a two-stage system that performs per-pixel segmentation followed by region detection. The output of the segmentation is used to search for highly probable  ...	6
Huimin Lu, Yujie Li, Xing Xu, Li He, Yun Li, Donald Dansereau, Seiichi Serikawa	2016/9/25	None	Abstract: Vision-based underwater navigation and object detection requires robust computer vision algorithms to operate in turbid water. Many conventional methods aimed at improving visibility in low turbid water. In this paper, we propose a novel contrast enhancement to enhance high turbid underwater images using descattering and color correction. The proposed enhancement method removes the scatter and preserves colors. In addition, as a rule to compare the performance of different image enhancement algorithms, a more  ...	2
Gucan Long, Laurent Kneip, Jose M Alvarez, Hongdong Li, Xiaohu Zhang, Qifeng Yu	2016/10/8	None	Abstract This work presents an unsupervised learning based approach to the ubiquitous computer vision problem of image matching. We start from the insight that the problem of frame interpolation implicitly solves for inter-frame correspondences. This permits the application of analysis-by-synthesis: we first train and apply a Convolutional Neural Network for frame interpolation, then obtain correspondences by inverting the learned CNN. The key benefit behind this strategy is that the CNN for frame interpolation can be trained in an  ...	7
Guosheng Lin, Chunhua Shen, Reid Ian, Anton van dan Hengel	2016	None	Abstract Recent advances in semantic image segmentation have mostly been achieved by training deep convolutional neural networks (CNNs). We show how to improve semantic segmentation through the use of contextual information; specifically, we explore'patch-patch'context between image regions, and'patch-background'context. For learning from the patch-patch context, we formulate Conditional Random Fields (CRFs) with CNN-based pairwise potential functions to capture semantic correlations between neighboring  ...	169
Junbin Liu, Sridha Sridharan, Clinton Fookes	2016/6/29	None	Abstract With recent advances in consumer electronics and the increasingly urgent need for public security, camera networks have evolved from their early role of providing simple and static monitoring to current complex systems capable of obtaining extensive video information for intelligent processing, such as target localization, identification, and tracking. In all cases, it is of vital importance that the optimal camera configuration (ie, optimal location, orientation, etc.) is determined before cameras are deployed as a suboptimal  ...	3
Zhibin Liao, Gustavo Carneiro	2016/3/7	None	Abstract: Deep feedforward neural networks with piecewise linear activations are currently producing the state-of-the-art results in several public datasets (eg, CIFAR-10, CIFAR-100, MNIST, and SVHN). The combination of deep learning models and piecewise linear activation functions allows for the estimation of exponentially complex functions with the use of a large number of subnetworks specialized in the classification of similar input examples. During the training process, these subnetworks avoid overfitting with an implicit  ...	7
Ben Letheren, Glen Montes, Tommaso Villa, Felipe Gonzalez	2016/3/5	None	Abstract: There is an increased interest on the use of UAVs for environmental research such as tracking bush fires, volcanic eruptions, chemical accidents or pollution sources. The aim of this paper is to describe the theory and results of a bio-inspired plume tracking algorithm. A method for generating sparse plumes in a virtual environment was also developed. Results indicated the ability of the algorithms to track plumes in 2D and 3D. The system has been tested with hardware in the loop (HIL) simulations and in flight using a CO2 gas  ...	3
Jürgen Leitner, William Chamberlain, Donald G Dansereau, Matthew Dunbabin, Markus Eich, Thierry Peynot, Jonathan Roberts, Raymond Russell, Niko Sünderhauf	2016/3	None	Abstract: We describe a hopping science payload solution designed to exploit the Moon's lower gravity to leap up to 20m above the surface. The entire solar-powered robot is compact enough to fit within a 10cm cube, whilst providing unique observation and mission capabilities by creating imagery during the hop. The LunaRoo concept is a proposed payload to fly onboard a Google Lunar XPrize entry. Its compact form is specifically designed for lunar exploration and science mission within the constraints given by  ...	2
Christopher Lehnert, Inkyu Sa, Christopher McCool, Ben Upcroft, Tristan Perez	2016/5/16	None	Abstract: This paper presents a method for estimating the 6DOF pose of sweet-pepper (capsicum) crops for autonomous harvesting via a robotic manipulator. The method uses the Kinect Fusion algorithm to robustly fuse RGB-D data from an eye-in-hand camera combined with a colour segmentation and clustering step to extract an accurate representation of the crop. The 6DOF pose of the sweet peppers is then estimated via a nonlinear least squares optimisation by fitting a superellipsoid to the segmented sweet pepper. The performance  ...	4
Huu Le, Tat-Jun Chin, David Suter	2016	None	Abstract Deformations of surfaces with the same intrinsic shape can often be described accurately by a conformal model. A major focus of computational conformal geometry is the estimation of the conformal mapping that aligns a given pair of object surfaces. The uniformization theorem en-ables this task to be acccomplished in a canonical 2D do-main, wherein the surfaces can be aligned using a M obius transformation. Current algorithms for estimating M obius transformations, however, often cannot provide satisfactory alignment  ...	0
	None	None	None	0
BG Vijay Kumar, Gustavo Carneiro, Ian Reid	2015/12/31	None	None	18
Piotr Koniusz, Anoop Cherian, Fatih Porikli	2016/4/1	None	Abstract In this paper, we explore tensor representations that can compactly capture higher-order relationships between skeleton joints for 3D action recognition. We first define RBF kernels on 3D joint sequences, which are then linearized to form kernel descriptors. The higher-order outer-products of these kernel descriptors form our tensor representations. We present two different kernels for action recognition, namely (i) a sequence compatibility kernel that captures the spatio-temporal compatibility of joints in one sequence against  ...	12
Piotr Koniusz, Anoop Cherian	2016	None	Abstract Super-symmetric tensors-a higher-order extension of scatter matrices-are becoming increasingly popular in machine learning and computer vision for modeling data statistics, co-occurrences, or even as visual descriptors. They were shown recently to outperform second-order approaches, however, the size of these tensors are exponential in the data dimensionality, which is a significant concern. In this paper, we study third-order super-symmetric tensor descriptors in the context of dictionary learning and sparse coding. For  ...	8
Laurent Kneip, Chris Sweeney, Richard Hartley	2016/3/7	None	Abstract: It is well-known that the relative pose problem can be generalized to non-central cameras. We present a further generalization, denoted the generalized relative pose and scale problem. It has surprising importance for classical problems such as solving similarity transformations for view-graph concatenation in hierarchical structure from motion and loop-closure in visual SLAM, both posed as a 2D-2D registration problem. The relative pose problem and all its generalizations constitute a family of similar symmetric eigenvalue  ...	1
Jae-Hak Kim, Cesar Cadena, Ian Reid	2016/5	None	Abstract: In this paper, we present a monocular Direct and Semi-dense SLAM (Simultaneous Localization And Mapping) system for rolling shutter cameras. In a rolling shutter camera, the pose is different for each row of each image, and this yields poor pose estimates and poor structure estimates when using a state-of-the-art semi-dense direct method designed for global shutter cameras. To address this issue in tracking, we model the smooth and continuous camera trajectory using a B-spline curve of degree k?? 1 for poses in the Lie  ...	3
Aisha Khan, Stephen Gould, Mathieu Salzmann	2016/10/8	None	Abstract We address the problem of counting cells in time-lapse microscopy images of developing human embryos. Cell counting is considered as an important step in analyzing biological phenomenon such as embryo viability. Traditional approaches to counting cells rely on hand crafted features and cannot fully take advantage of the growth in data set sizes. In this paper, we propose a framework to automatically count the number of cells in developing human embryos. The framework employs a deep convolutional neural  ...	2
Tor A Johansen, Tristan Perez	2016/6/7	None	Abstract: Autonomous ships require a sense-and-collision-avoidance functionality based on surveillance of the ocean surface in order to detect unmapped and potentially non-cooperative obstacles and hazards, and to engage into evasive manoeuvres to avoid impending collisions. In this paper, we study the concept of using an autonomous ship being assisted by an unmanned aerial surveillance system (UASS) that provides information to the ship in order to implement collision avoidance in compliance with the Convention on the  ...	3
Pan Ji, Hongdong Li, Mathieu Salzmann, Yiran Zhong	2016/6/26	None	Abstract Feature tracking is a fundamental problem in computer vision with applications in various tasks including 3D reconstruction and visual SLAM. While many methods have been devoted to making these tasks robust to noise and outliers, less attention has been attracted to improving the feature tracking itself. This paper introduces a novel multi-body feature tracker that takes advantage of the multi-body rigidity assumption to improve tracking robustness. A conventional approach to addressing this problem would consist of  ...	2
Xiaolei Hou, Xiaohua Wang, Robert Mahony	2016/7/27	None	Abstract: In this paper, we present a novel semi-autonomous shared control framework based on an admittance configured haptic interface for bilateral teleoperation of VTOL aerial robots. A haptics-aided path planner and a virtual fixture based dynamic kinesthetic boundary (VFDKB) are proposed to better assist pilots to navigate through complex environments and perceive obstacle and path boundary. By combining the autonomous path planner and VFDKB, the novel framework maximizes autonomy and maintains  ...	0
Xuefei He, Chuong Vinh Nguyen, Mrinalini Pratap, Yujie Zheng, Yi Wang, David R Nisbet, Melanie Rug, Alexander G Maier, Woei Ming Lee	2016/12/9	None	abstract Here we propose a region-recognition approach with iterative thresholding, which is adaptively tailored to extract the appropriate region or shape of spatial frequency. In order to justify the method, we tested it with different samples and imaging conditions (different objectives). We demonstrate that our method provides a useful method for rapid imaging of cellular dynamics in microfluidic and cell cultures.©(2016) COPYRIGHT Society of Photo-Optical Instrumentation Engineers (SPIE). Downloading of the abstract is permitted for  ...	0
Minh-Duc Hua, Jochen Trumpf, Tarek Hamel, Robert Mahony, Pascal Morin	2016/6/9	None	Abstract: This paper presents a new algorithm for online estimation of a sequence of homographies applicable to image sequences obtained from robotic vehicles equipped with vision sensors. The approach taken exploits the underlying Special Linear group structure of the set of homographies along with gyroscope measurements and direct point-feature correspondences between images to develop temporal filter for the homography estimate. Theoretical analysis and experimental results are provided to demonstrate the robustness  ...	0
Ben Harwood, Tom Drummond	2016	None	Abstract We present a new method for approximate nearest neighbour search on large datasets of high dimensional feature vectors, such as SIFT or GIST descriptors. Our approach constructs a directed graph that can be efficiently explored for nearest neighbour queries. Each vertex in this graph represents a feature vector from the dataset being searched. The directed edges are computed by exploiting the fact that, for these datasets, the intrinsic dimensionality of the local manifold-like structure formed by the elements of  ...	8
Afsaneh Ghasemi, Simon Denman, Sridha Sridharan, Clinton Fookes	2016/3/7	None	Abstract: Deep, intuitive understanding of facial motions has the potential to provide an intelligent facial expression system as well as a unique encoding of the dynamics of facial actions. The most promising existing approaches rely on extracting hand crafted features; and existing approaches typically work best in constrained conditions and do not generalise well to varying environmental conditions which make them poorly suited to applications such as real-time human robot interactions. In this paper, we propose a multi-label deep  ...	0
ZongYuan Ge, Chris McCool, Conrad Sanderson, Peng Wang, Lingqiao Liu, Ian Reid, Peter Corke	2016/11/30	None	Abstract: Fine-grained classification is a relatively new field that has concentrated on using information from a single image, while ignoring the enormous potential of using video data to improve classification. In this work we present the novel task of video-based fine-grained object classification, propose a corresponding new video dataset, and perform a systematic study of several recent deep convolutional neural network (DCNN) based approaches, which we specifically adapt to the task. We evaluate three-dimensional DCNNs, two- ...	0
ZongYuan Ge, Alex Bewley, Christopher McCool, Peter Corke, Ben Upcroft, Conrad Sanderson	2016/3/7	None	Abstract: We present a novel deep convolutional neural network (DCNN) system for fine-grained image classification, called a mixture of DCNNs (MixDCNN). The fine-grained image classification problem is characterised by large intra-class variations and small inter-class variations. To overcome these problems our proposed MixDCNN system partitions images into K subsets of similar images and learns an expert DCNN for each subset. The output from each of the K DCNNs is combined to form a single classification decision. In  ...	8
Ravi Garg, Gustavo Carneiro, Ian Reid	2016/10/8	None	Abstract A significant weakness of most current deep Convolutional Neural Networks is the need to train them using vast amounts of manually labelled data. In this work we propose a unsupervised framework to learn a deep convolutional neural network for single view depth prediction, without requiring a pre-training stage or annotated ground-truth depths. We achieve this by training the network in a manner analogous to an autoencoder. At training time we consider a pair of images, source and target, with small, known camera motion  ...	28
Kirill Frolov, Jurgen Fripp, Chuong V Nguyen, Robert Furbank, Geoff Bull, Peter Kuffner, Helen Daily, Xavier Sirault	2016/11/30	None	Abstract: In recent years, the use of imaging based, non-invasive, and non-destructive plant phenotyping platforms have become popular. The analysis of the imaging data acquired from these platforms is still challenging. Current, 2D methods are limited in the information available, while 3D methods are more challenging to analyze. Plants like wheat are particularly challenging due to their thin leaves which are often in contact or occluded. In this paper, we introduce a method to more reliably reconstruct the complete 3D mesh from  ...	0
Basura Fernando, Peter Anderson, Marcus Hutter, Stephen Gould	2016	None	Abstract We present hierarchical rank pooling, a video sequence encoding method for activity recognition. It consists of a network of rank pooling functions which captures the dynamics of rich convolutional neural network features within a video sequence. By stacking non-linear feature functions and rank pooling over one another, we obtain a high capacity dynamic encoding mechanism, which is used for action recognition. We present a method for jointly learning the video representation and activity classifier parameters. Our method  ...	28
Anders Eriksson, John Bastian, Tat-Jun Chin, Mats Isaksson	2016	None	Abstract In this paper we study large-scale optimization problems in multi-view geometry, in particular the Bundle Adjustment problem. In its conventional formulation, the complexity of existing solvers scale poorly with problem size, hence this component of the Structure-from-Motion pipeline can quickly become a bottle-neck. Here we present a novel formulation for solving bundle adjustment in a truly distributed manner using consensus based optimization methods. Our algorithm is presented with a concise derivation based on proximal splitting,  ...	2
Matthew Dunbabin	2016	None	Abstract Accurately quantifying total greenhouse gas emissions (eg methane) from natural systems such as lakes, reservoirs and wetlands requires the spatial-temporal measurement of both diffusive and ebullitive (bubbling) emissions. Traditional, manual, measurement techniques provide only limited localised assessment of methane flux, often introducing significant errors when extrapolated to the whole-of-system. In this paper, we directly address these current sampling limitations and present a novel multiple robotic boat  ...	4
Dingfu Zhou, Yuchao Dai, Hongdong Li	2016/6/19	None	Abstract: Recovering absolute scale (ie metric information) from monocular vision system is a very challenging problem yet is highly desirable for vision-based autonomous driving. This paper proposes a new method for scale recovery, based on the idea of knowing camera height (relative to ground-plane). While this idea of using known camera height is not new in this context, existing implementations of this idea suffer significantly from severe numerical instability arisen in the ground plane homography decomposition stage. Our novel  ...	0
Thanuja Dharmasiri, Vincent Lui, Tom Drummond	2016	None	Abstract: In this paper, we present MO-SLAM, a novel visual SLAM system that is capable of detecting duplicate objects in the scene during run-time without requiring an offline training stage to pre-populate a database of objects. Instead, we propose a novel method to detect landmarks that belong to duplicate objects. Further, we show how landmarks belonging to duplicate objects can be converted to first-order entities which generate additional constraints for optimizing the map. We evaluate the performance of MO-SLAM with  ...	0
Simone De Marco, Lorenzo Marconi, Tarek Hamel, Robert Mahony	2016/12/12	None	Abstract: This paper addresses the output regulation problem of rigid bodies whose kinematic configuration space lies on the Special Euclidean Group SE (3). Reference trajectories to be tracked are generated by an autonomous system, referred to as exosystem, defined on the Special Euclidean Group as well. Only partial relative pose measurements associated to the “natural” linear left group action on SE (3) along with the pose and the velocity of the controlled body are available. The proposed control action embeds a copy  ...	0
Yuchao Dai, Hongdong Li, Laurent Kneip	2016	None	Abstract The vast majority of modern consumer-grade cameras employ a rolling shutter mechanism. In dynamic geometric computer vision applications such as visual SLAM, the so-called rolling shutter effect therefore needs to be properly taken into account. A dedicated relative pose solver appears to be the first problem to solve, as it is of eminent importance to bootstrap any derivation of multi-view geometry. However, despite its significance, it has received inadequate attention to date. This paper presents a detailed investigation of the  ...	1
Yuchao Dai, Hongdong Li	2016/11/30	None	Abstract: Given multi-view correspondences, it has been shown that 3D non-rigid structure can be recovered through factorization based techniques. However, establishing reliable correspondences across multi-view images of non-rigid structure is not an easy task. Existing methods solve multi-view correspondences and 3D non-rigid structure in sequel, which cannot exploit the crossover constraints in each sub-problem (\ie, constraints in non-rigid structure has not been enforced in establishing multi-view correspondences and  ...	0
Tat-Jun Chin, Yang Heng Kee, Anders Eriksson, Frank Neumann	2016	None	Abstract The maximum consensus problem is fundamentally important to robust geometric fitting in computer vision. Solving the problem exactly is computationally demanding, and the effort required increases rapidly with the problem size. Although randomized algorithms are much more efficient, the optimality of the solution is not guaranteed. Towards the goal of solving maximum consensus exactly, we present guaranteed outlier removal as a technique to reduce the runtime of exact algorithms. Specifically, before conducting global  ...	3
William Chamberlain, Juergen Leitner, Tom Drummond, Peter Corke	2016/6/21	None	Abstract: Robotic vision is limited by line of sight and on-board camera capabilities. Robots can acquire video or images from remote cameras, but processing additional data has a computational burden. This paper applies the Distributed Robotic Vision Service, DRVS, to robot path planning using data outside line-of-sight of the robot. DRVS implements a distributed visual object detection service to distributes the computation to remote camera nodes with processing capabilities. Robots request task-specific object detection from  ...	1
Hakan Bilen, Basura Fernando, Efstratios Gavves, Andrea Vedaldi, Stephen Gould	2016	None	Abstract We introduce the concept of dynamic image, a novel compact representation of videos useful for video analysis especially when convolutional neural networks (CNNs) are used. The dynamic image is based on the rank pooling concept and is obtained through the parameters of a ranking machine that encodes the temporal evolution of the frames of the video. Dynamic images are obtained by directly applying rank pooling on the raw image pixels of a video producing a single RGB image per video. This idea is simple but  ...	58
Alex Bewley, Lionel Ott, Fabio Ramos, Ben Upcroft	2016/5/16	None	Abstract: This paper presents a self-supervised approach for learning to associate object detections in a video sequence as often required in tracking-by-detection systems. In this paper we focus on learning an affinity model to estimate the data association cost, which can adapt to different situations by exploiting the sequential nature of video data. We also propose a framework for gathering additional training samples at test time with high variation in visual appearance, naturally inherent in large temporal windows. Reinforcing the model  ...	7
Alex Bewley, Zongyuan Ge, Lionel Ott, Fabio Ramos, Ben Upcroft	2016/9/25	None	Abstract: This paper explores a pragmatic approach to multiple object tracking where the main focus is to associate objects efficiently for online and realtime applications. To this end, detection quality is identified as a key factor influencing tracking performance, where changing the detector can improve tracking by up to 18.9%. Despite only using a rudimentary combination of familiar techniques such as the Kalman Filter and Hungarian algorithm for the tracking components, this approach achieves an accuracy comparable to  ...	13
Soudeh Kasiri Behendi, Stuart Morgan, Clinton B Fookes	2016	None	Abstract Computer vision offers a growing capacity to detect and classify actions in a large range of sports. Since combat sports are highly dynamic and physically demanding, it is difficult to measure features of performance from competition in a safe and practical way. Also, coaches frequently wish to measure the performance characteristics of other competitors. For these reasons it is desirable to be able to measure features of competitive performance without using sensors or physical devices. We present a non-invasive  ...	4
Peter Anderson, Basura Fernando, Mark Johnson, Stephen Gould	2016/10	None	Abstract There is considerable interest in the task of automatically generating image captions. However, evaluation is challenging. Existing automatic evaluation metrics are primarily sensitive to n-gram overlap, which is neither necessary nor sufficient for the task of simulating human judgment. We hypothesize that semantic propositional content is an important component of human caption evaluation, and propose a new automated caption evaluation metric defined over scene graphs coined SPICE. Extensive evaluations across  ...	28
Guillaume Allibert, Robert Mahony, Moses Bangura	2016/5/16	None	Abstract: Flight performance of aerial robotic vehicles is critically dependent on the quality of the state estimates provided by onboard sensor systems. The attitude estimation problem has been extensively studied over the last ten years and the development of low complexity, high performance, robust non-linear observers for attitude has been one of the enabling technologies fueling the growth of small scale aerial robotic systems. The velocity aided attitude estimation problem, that is simultaneous estimation of attitude and linear velocity  ...	3
Iman Abbasnejad, Sridha Sridharan, Simon Denman, Clinton Fookes, Simon Lucey	2016/11/30	None	Abstract: In this paper the problem of complex event detection is addressed. Existing event detection methods are limited to features that are extracted from local spatial or spatio-temporal patches from the videos. However, this makes the model more vulnerable to the events that have similar concepts with different actions eg" Open drawer" and" Open cupboard". Furthermore, current methods typically assume that events have already been segmented from the video stream, and do not generalize well to events with unknown  ...	3
Thalaiyasingam Ajanthan, Richard Hartley, Mathieu Salzmann	2016	None	Abstract Multi-label submodular Markov Random Fields (MRFs) have been shown to be solvable using max-flow based on an encoding of the labels proposed by Ishikawa, in which each variable X_i is represented by l nodes (where l is the number of labels) arranged in a column. However, this method in general requires 2l^ 2 edges for each pair of neighbouring variables. This makes it inapplicable to realistic problems with many variables and labels, due to excessive memory requirement. In this paper, we introduce a variant of the max- ...	0
Lei Zhang, Wei Wei, Yanning Zhang, Chunhua Shen, Anton van den Hengel, Qinfeng Shi	2016/12	None	Abstract: The ability to accurately represent a hyperspectral image (HSI) as a combination of a small number of elements from an appropriate dictionary underpins much of the recent progress in hyperspectral compressive sensing (HCS). Preserving structure in the sparse representation is critical to achieving an accurate reconstruction but has thus far only been partially exploited because existing methods assume a predefined dictionary. To address this problem, a structured sparsity-based hyperspectral blind compressive sensing  ...	3
Jianfeng Dong, Xiao-Jiao Mao, Chunhua Shen, Yu-Bin Yang	2016/11/28	None	Abstract: Convolutional neural networks (CNNs) have shown their power on many computer vision tasks. However, there are still some limitations, including their dependency to large scale labeled training data and sensitivity to weight initialization. In this paper, we try to address these two problems by proposing a simple yet powerful CNN based denoising auto-encoder which can be trained end-to-end in an unsupervised manner. The network architecture we employ is a fully convolutional auto-encoder with symmetric encoder- ...	2
Haibo Yu, Liao Wu, Keyu Wu, Hongliang Ren	2016/7	None	Abstract: Minimally invasive surgery-based nasopharyngeal cancer treatment is promising, but currently, it is not a common treatment choice because of the absence of suitable tools. In this letter, a multi-channel concentric tube robot is proposed for the treatment of nasopharyngeal cancer based on natural orifice translumenal endoscopic surgery. The proposed system has three channels, ie, two manipulation channels and one vision channel, and all the three channels are confined by a 10 mm active sheath. The robot is  ...	7
	None	None	None	0
Jingxin Xu, Simon Denman, Clinton Fookes, Sridha Sridharan	2016/7/15	None	Abstract Video surveillance infrastructure has been widely installed in public places for security purposes. However, live video feeds are typically monitored by human staff, making the detection of important events as they occur difficult. As such, an expert system that can automatically detect events of interest in surveillance footage is highly desirable. Although a number of approaches have been proposed, they have significant limitations: supervised approaches, which can detect a specific event, ideally require a large number of samples  ...	7
Guobao Xiao, Hanzi Wang, Taotao Lai, David Suter	2016/12/31	None	Abstract In this paper, we propose a novel hypergraph based method (called HF) to fit and segment multi-structural data. The proposed HF formulates the geometric model fitting problem as a hypergraph partition problem based on a novel hypergraph model. In the hypergraph model, vertices represent data points and hyperedges denote model hypotheses. The hypergraph, with large and “data-determined” degrees of hyperedges, can express the complex relationships between model hypotheses and data points. In addition ...	0
Liao Wu, Jiaole Wang, Lin Qi, Keyu Wu, Hongliang Ren, Max Q-H Meng	2016/4	None	Abstract: Multirobot comanipulation shows great potential in surpassing the limitations of single-robot manipulation in complicated tasks such as robotic surgeries. However, a dynamic multirobot setup in unstructured environments poses great uncertainties in robot configurations. Therefore, the coordination relationships between the end-effectors and other devices, such as cameras (hand-eye calibration) and tools (tool-flange calibration), as well as the relationships among the base frames (robot-robot calibration) have to be  ...	2
Michael Warren, Peter Corke, Ben Upcroft	2016/4	None	Visual Odometry is a key technology for robust and accurate navigation of unmanned aerial vehicles in a number of low altitude applications (&lt; 120 m), particularly in environments where access to a global positioning system is possible, but not guaranteed. Navigating via vision alone reduces dependence on a global positioning system and other global navigation satellite systems, enhancing navigation robustness even in the presence of jamming, spoofing or long dropouts. To date, however, most demonstrations of visual  ...	8
Xiaoqin Wang, Yasar Ahmet Şekercioğlu, Tom Drummond, Enrico Natalizio, Isabelle Fantoni, Vincent Frémont	2016/4	None	Abstract: We propose a new method, called 3-D image warping-based depth video compression (IW-DVC), for fast and efficient compression of depth images captured by mobile RGB-D sensors. The emergence of low-cost RGB-D sensors has created opportunities to find new solutions for a number of computer vision and networked robotics problems, such as 3-D map building, immersive telepresence, or remote sensing. However, efficient transmission and storage of depth data still presents a challenging task to the  ...	0
Wenguan Wang, Jianbing Shen, Ling Shao, Fatih Porikli	2016/11	None	Abstract: In this paper, we show that large annotated data sets have great potential to provide strong priors for saliency estimation rather than merely serving for benchmark evaluations. To this end, we present a novel image saliency detection method called saliency transfer. Given an input image, we first retrieve a support set of best matches from the large database of saliency annotated images. Then, we assign the transitional saliency scores by warping the support set annotations onto the input image according to  ...	9
Guosheng Lin, Chunhua Shen, Ian Reid, Anton van den Hengel	2016	None	Abstract Recent advances in semantic image segmentation have mostly been achieved by training deep convolutional neural networks (CNNs). We show how to improve semantic segmentation through the use of contextual information; specifically, we explore'patch-patch'context between image regions, and'patch-background'context. For learning from the patch-patch context, we formulate Conditional Random Fields (CRFs) with CNN-based pairwise potential functions to capture semantic correlations between neighboring  ...	169
Ruwan B Tennakoon, Alireza Bab-Hadiashar, Zhenwei Cao, Reza Hoseinnezhad, David Suter	2016/2/1	None	Abstract: Identifying the underlying model in a set of data contaminated by noise and outliers is a fundamental task in computer vision. The cost function associated with such tasks is often highly complex, hence in most cases only an approximate solution is obtained by evaluating the cost function on discrete locations in the parameter (hypothesis) space. To be successful at least one hypothesis has to be in the vicinity of the solution. Due to noise hypotheses generated by minimal subsets can be far from the underlying model, even  ...	11
Gavin Suddrey, Christopher Lehnert, Markus Eich, Frederic Maire, Jonathan Roberts	2017/1	None	Abstract: Natural language provides a convenient means of communicating information, and as such, is an ideal medium for enabling nonexpert users to teach robots novel tasks. However, in order to take advantage of natural language, a series of challenges must first be overcome. These challenges include the need to a) generalize learnt tasks to novel scenarios without retraining, b) resolve problems encountered during task execution, and c) derive implicit information from knowledge about the domain. To solve these challenges,  ...	1
Peter Stratton, Michael Hasselmo, Michael Milford	2016/11/15	None	Abstract Complex brains evolved in order to comprehend and interact with complex environments in the real world. Despite significant progress in our understanding of perceptual representations in the brain, our understanding of how the brain carries out higher level processing remains largely superficial. This disconnect is understandable, since the direct mapping of sensory inputs to perceptual states is readily observed, while mappings between (unknown) stages of processing and intermediate neural states is not.  ...	1
Geoff Stacey, Robert Mahony	2016/2	None	Abstract: In this technical note, we present a framework for the formation control of dynamic vehicles in R 3, using partial measurements of relative position. The proposed control scheme implements virtual mechanical couplings on the available sensor measurements, and is developed using a passivity-based design approach with considerable insight from the bondgraph modelling formalism. In particular, we present a novel passive adaptive compensation technique to estimate the unknown state information required for the key  ...	2
Whye Leon Seng, Jan Carlo Barca, Y Ahmet Şekercioğlu	2016/6	None	Abstract A distributed control mechanism for ground moving nonholonomic robots is proposed. It enables a group of mobile robots to autonomously manage formation shapes while navigating through environments with obstacles. The mechanism consists of two stages, with the first being formation control that allows basic formation shapes to be maintained without the need of any inter-robot communication. It is followed by obstacle avoidance, which is designed with maintaining the formation in mind. Every robot is  ...	2
Ingo Schiffner, Tristan Perez, Mandyam V Srinivasan	2016/9/28	None	Abstract We have investigated how birds avoid mid-air collisions during head-on encounters. Trajectories of birds flying towards each other in a tunnel were recorded using high speed video cameras. Analysis and modelling of the data suggest two simple strategies for collision avoidance:(a) each bird veers to its right and (b) each bird changes its altitude relative to the other bird according to a preset preference. Both strategies suggest simple rules by which collisions can be avoided in head-on encounters by two agents, be they  ...	1
Sajib Kumar Saha, Basura Fernando, Jorge Cuadros, Di Xiao, Yogesan Kanagasingam	2017/3/7	None	Abstract: Purpose To develop a computer based method for the automated assessment of image quality in the context of diabetic retinopathy (DR) to guide the photographer. Methods A deep learning framework was trained to grade the images automatically. A large representative set of 7000 color fundus images were used for the experiment which were obtained from the EyePACS that were made available by the California Healthcare Foundation. Three retinal image analysis experts were employed to categorize these  ...	0
Inkyu Sa, Zongyuan Ge, Feras Dayoub, Ben Upcroft, Tristan Perez, Chris McCool	2016/8/3	None	This paper presents a novel approach to fruit detection using deep convolutional neural networks. The aim is to build an accurate, fast and reliable fruit detection system, which is a vital element of an autonomous agricultural robotic platform; it is a key element for fruit yield estimation and automated harvesting. Recent work in deep neural networks has led to the development of a state-of-the-art object detector termed Faster Region-based CNN (Faster R-CNN). We adapt this model, through transfer learning, for the task of fruit detection using  ...	7
Jhony K Pontes, Alceu S Britto, Clinton Fookes, Alessandro L Koerich	2016/6/30	None	Abstract Age estimation from facial images is increasingly receiving attention to solve age-based access control, age-adaptive targeted marketing, amongst other applications. Since even humans can be induced in error due to the complex biological processes involved, finding a robust method remains a research challenge today. In this paper, we propose a new framework for the integration of Active Appearance Models (AAM), Local Binary Patterns (LBP), Gabor wavelets (GW) and Local Phase Quantization (LPQ) in order to  ...	10
Edward Pepperell, Peter Corke, Michael Milford	2016/8	None	Vision-based place recognition is becoming an increasingly viable component of navigation systems for autonomous robots and personal aids. However, attaining robustness to variations in environmental conditions—such as time of day, weather and season—and camera viewpoint remains a major challenge. Featureless, sequence-based place recognition techniques have demonstrated promise, but often rely on long image sequences, manually-tuned parameters and exhaustive sequence match searching  ...	3
	None	None	None	0
	None	None	None	0
	None	None	None	0
