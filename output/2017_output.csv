Authors	Publication Date	Publisher	Description	Citations
Sean M McMahon, Niko Sunderhauf, Ben Upcroft, Michael J Milford	2017/6/26	None	Abstract: Trip hazards are a significant contributor to accidents on construction and manufacturing sites, where over a third of Australian workplace injuries occur [1]. Current safety inspections are labour intensive and limited by human fallibility, making automation of trip hazard detection appealing from both a safety and economic perspective. Trip hazards present an interesting challenge to modern learning techniques because they are defined as much by affordance as by object type; for example wires on a table are not a trip hazard ...	0
Timothy L Molloy, Justin M Kennedy, Jason J Ford	2017/10	None	Abstract: Quickly detecting changes in the statistical behavior of measurements is important in many applications of control engineering involving fault detection and process monitoring. In this letter, we pose and solve minimax robust Lorden and Bayesian quickest change detection problems for situations where the cost of detection delays compounds exponentially. We show that the detection rules that solve our robust quickest change detection problems are also the rules that solve the standard (non-robust) problems  ...	0
Sourav Garg, Adam Jacobson, Swagat Kumar, Michael Milford	2017/6/22	None	Abstract: The place recognition problem comprises two distinct subproblems; recognizing a specific location in the world (" specific" or" ordinary" place recognition) and recognizing the type of place (place categorization). Both are important competencies for mobile robots and have each received significant attention in the robotics and computer vision community, but usually as separate areas of investigation. In this paper, we leverage the powerful complementary nature of place recognition and place categorization processes to create a  ...	0
Dmitry Bratanov, Luis Mejias, Jason J Ford	2017/6/13	None	This paper presents a study of near collision course engagements between a Cessna 172R aircraft and a ScanEagle UAV carrying a custom built vision-based sense-and-avoid system. Vision-based systems are an attractive solution for the sense-and-avoid problem because of size, weight and power considerations. We present post flight test analysis that shows our detection system successfully detecting an approaching Cessna aircraft in all 15 flight test encounters at ranges greater than 1500 m, with no false alarms events. Moreover, this  ...	0
Kien Nguyen, Clinton Fookes, Raghavender Jillela, Sridha Sridharan, Arun Ross	2017/7/4	None	Abstract The term “iris” refers to the highly textured annular portion of the human eye that is externally visible. An iris recognition system exploits the richness of these textural patterns to distinguish individuals. Iris recognition systems are being used in a number of human recognition applications such as access control, national ID schemes, border control, etc. To capture the rich textural information of the iris pattern regardless of the eye color, traditional iris recognition systems utilize near-infrared (NIR) sensors to acquire images of the iris.  ...	0
Viorela Ila, Lukas Polok, Marek Solony, Pavel Svoboda	2017/2	None	The most common way to deal with the uncertainty present in noisy sensorial perception and action is to model the problem with a probabilistic framework. Maximum likelihood estimation is a well-known estimation method used in many robotic and computer vision applications. Under Gaussian assumption, the maximum likelihood estimation converts to a nonlinear least squares problem. Efficient solutions to nonlinear least squares exist and they are based on iteratively solving sparse linear systems until convergence. In general, the  ...	1
Basura Fernando, Efstratios Gavves, José Oramas, Amir Ghodrati, Tinne Tuytelaars	2017/4/1	None	Abstract: We propose a function-based temporal pooling method that captures the latent structure of the video sequence data-eg, how frame-level features evolve over time in a video. We show how the parameters of a function that has been fit to the video data can serve as a robust new video representation. As a specific example, we learn a pooling function via ranking machines. By learning to rank the frame-level features of a video in chronological order, we obtain a new representation that captures the video-wide  ...	30
Riku Shigematsu, David Feng, Shaodi You, Nick Barnes	2017/5/10	None	Abstract: Recently, deep Convolutional Neural Networks (CNN) have demonstrated strong performance on RGB salient object detection. Although, depth information can help improve detection results, the exploration of CNNs for RGB-D salient object detection remains limited. Here we propose a novel deep CNN architecture for RGB-D salient object detection that exploits high-level, mid-level, and low level features. Further, we present novel depth features that capture the ideas of background enclosure and depth contrast that are  ...	0
Chuong V Nguyen, Michael Milford, Robert Mahony	2017/1/16	None	Abstract: Current self-driving car systems operate well in sunny weather but struggle in adverse conditions. One of the most commonly encountered adverse conditions involves water on the road caused by rain, sleet, melting snow or flooding. While some advances have been made in using conventional RGB camera and LIDAR technology for detecting water hazards, other sources of information such as polarization offer a promising and potentially superior approach to this problem in terms of performance and cost. In this  ...	0
	None	None	None	0
Fangyi Zhang, Jürgen Leitner, Michael Milford, Peter I Corke	2017/5/15	None	Abstract: This paper introduces an end-to-end fine-tuning method to improve hand-eye coordination in modular deep visuo-motor policies (modular networks) where each module is trained independently. Benefiting from weighted losses, the fine-tuning method significantly improves the performance of the policies for a robotic planar reaching task.	0
	None	None	None	0
Peter Corke	2017/6/23	None	Robotic vision, the combination of robotics and computer vision, involves the application of computer algorithms to data acquired from sensors. The research community has developed a large body of such algorithms but for a newcomer to the field this can be quite daunting. For over 20 years the author has maintained two open-source MATLAB® Toolboxes, one for robotics and one for vision. They provide implementations of many important algorithms and allow users to work with real problems, not just trivial examples. This book makes the  ...	0
Anoop Cherian, Suvrit Sra, Richard Hartley	2017/5/24	None	Abstract: Representations that can compactly and effectively capture temporal evolution of semantic content are important to machine learning algorithms that operate on multi-variate time-series data. We investigate such representations motivated by the task of human action recognition. Here each data instance is encoded by a multivariate feature (such as via a deep CNN) where action dynamics are characterized by their variations in time. As these features are often non-linear, we propose a novel pooling method, kernelized rank  ...	0
Florent Le Bras, Tarek Hamel, Robert Mahony, Claude Samson	2017	None	Abstract This chapter considers the questions of observability and design of observers for position estimates of an object moving in R^ n R n. The scenario considered assumes a possibly biased measurement of velocity along with bearing or direction measurements to one or multiple fixed points in the environment. The motivating example is a robot moving in either two-or three-dimensional space with a sensor, such as a camera Camera, capable of providing bearing but not distance to observed fixed points in the environment. We  ...	0
Tong Shen, Guosheng Lin, Lingqiao Liu, Chunhua Shen, Ian Reid	2017/5/25	None	Abstract: Training a Fully Convolutional Network (FCN) for semantic segmentation requires a large number of pixel-level masks, which involves a large amount of human labour and time for annotation. In contrast, image-level labels are much easier to obtain. In this work, we propose a novel method for weakly supervised semantic segmentation with only image-level labels. The method relies on a large scale co-segmentation framework that can produce object masks for a group of images containing objects belonging to the same semantic  ...	0
Benjamin J Meyer, Ben Harwood, Tom Drummond	2017/5/27	None	Abstract: We present a radial basis function solver for convolutional neural networks that can be directly applied to both image classification and distance metric learning problems. Our method treats all training features from a deep neural network as radial basis function centres and computes loss by summing the influence of a feature's nearby centres in the embedding space. Having a radial basis function centred on each training feature is made scalable by treating it as an approximate nearest neighbour search problem. End-to-end  ...	0
Basura Fernando, Stephen Gould	2017/5/30	None	Abstract: In this work, we present novel temporal encoding methods for action and activity classification by extending the unsupervised rank pooling temporal encoding method in two ways. First, we present" discriminative rank pooling" in which the shared weights of our video representation and the parameters of the action classifiers are estimated jointly for a given training dataset of labelled vector sequences using a bilevel optimization formulation of the learning problem. When the frame level features vectors are obtained from a  ...	0
Bohan Zhuang, Qi Wu, Chunhua Shen, Ian Reid, Anton van den Hengel	2017/5/28	None	Abstract: Visual relationship detection aims to capture interactions between pairs of objects in images. Relationships between objects and humans represent a particularly important subset of this problem, with implications for challenges such as understanding human behaviour, and identifying affordances, amongst others. In addressing this problem we first construct a large-scale human-centric visual relationship detection dataset (HCVRD), which provides many more types of relationship annotation (nearly 10K categories) than the  ...	0
Zhibin Liao, Gustavo Carneiro	2017/5/31	None	Abstract We introduce a new deep convolutional neural network (ConvNet) module that promotes competition amongst a set of convolutional filters of multiple sizes. This new module is inspired by the inception module, where we replace the original collaborative pooling stage (consisting of a concatenation of the multiple size filter outputs) by a competitive pooling represented by a maxout activation unit. This extension has the following two objectives: 1) the selection of the maximum response amongst the multiple  ...	0
Zheng Li, Liao Wu, Hongliang Ren, Haoyong Yu	2017/1/31	None	Abstract Robot manipulators are increasingly used in minimally invasive surgery (MIS). They are required to have small size, wide workspace, adequate dexterity and payload ability when operating in confined surgical cavity. Snake-like flexible manipulators are well suited to these applications. However, conventional fully actuated snake-like flexible manipulators are difficult to miniaturize and even after miniaturization the payload is very limited. The alternative is to use underactuated snake-like flexible manipulators. Three prevailing  ...	3
Liao Wu, Hongliang Ren	2017/1	None	Abstract: When a robot is required to perform specific tasks defined in the world frame, there is a need for finding the coordinate transformation between the kinematic base frame of the robot and the world frame. The kinematic base frame used by the robot controller to define and evaluate the kinematics may deviate from the mechanical base frame constructed based on structural features. Besides, by using kinematic modeling rules such as the product of exponentials (POE) formula, the base frame can be arbitrarily located, and does  ...	3
Alejandro Donaire, Jose Guadalupe Romero, Tristan Perez	2017/3/31	None	Abstract In this paper we present a dynamic model of marine vehicles in both body-fixed and inertial momentum coordinates using port-Hamiltonian framework. The dynamics in body-fixed coordinates have a particular structure of the mass matrix that allows the application of passivity-based control design developed for robust energy shaping stabilisation of mechanical systems described in terms of generalised coordinates. As an example of application, we follow this methodology to design a passivity-based controller with integral  ...	0
Christopher Lehnert, Andrew English, Christopher McCool, Adam W Tow, Tristan Perez	2017/4	None	Abstract: In this letter, we present a new robotic harvester (Harvey) that can autonomously harvest sweet pepper in protected cropping environments. Our approach combines effective vision algorithms with a novel end-effector design to enable successful harvesting of sweet peppers. Initial field trials in protected cropping environments, with two cultivar, demonstrate the efficacy of this approach achieving a 46% success rate for unmodified crop, and 58% for modified crop. Furthermore, for the more favourable cultivar we were also able to detach  ...	2
Franz Andert, Nikolaus Ammann, Stefan Krause, Sven Lorenz, Dmitry Bratanov, Luis Mejias	2017	None	Abstract This paper presents an optical-aided navigation method for automatic flights where satellite navigation might be disturbed. The proposed solution follows common approaches where satellite position updates are replaced with measurements from environment sensors such as a camera, lidar or radar as required. The alternative positioning is determined by a localization and mapping (SLAM) algorithm that handles 2D feature inputs from monocular camera images as well as 3D inputs from camera images that are augmented by range  ...	0
David Crofts, Troy S Bruggemann, Jason J Ford	2017/2/26	None	An enhanced level of autonomy for UAVs is desirable when behaviours more sophisticated than simply following waypoint presets are desired. Behaviour Trees (BT) provide a decision tree like approach for developers to efficiently implement these sophisticated behaviours through a robust, modular, scalable framework. This paper presents a framework for easy development of BTs which implements autonomous unmanned aerial vehicle (UAV) behaviours, building upon the existing Java Behaviour Tree (JBT) software for video  ...	0
Timothy L Molloy, Jason J Ford, Tristan Perez	2017/7/14	None	We consider the problem of computing parameters of player cost functions in discrete-time nonzero-sum noncooperative dynamic games from open-loop Nash equilibria. Although similar inverse problems have been investigated in the optimal control literature where there is a single player (or decision maker), there has been limited attention given to the inverse dynamic game problem with multiple (competing) players. By exploiting the minimum principle of optimal control, we propose a method of inverse dynamic games for when the  ...	0
Daniel L Bongiorno, Mitch Bryson, Tom CL Bridge, Donald G Dansereau, Stefan B Williams	2017/3/1	None	Abstract We present a new method for in situ high-resolution hyperspectral mapping of the seafloor utilizing a spectrometer colocated and coregistered with a high-resolution color stereo camera system onboard an autonomous underwater vehicle (AUV). Hyperspectral imagery data have been used extensively for mapping and distinguishing marine seafloor habitats and organisms from above-water platforms (such as satellites and aircraft), but at low spatial resolutions and at shallow water depths (&lt; 10 m). The use of hyperspectral  ...	0
Alex Bewley, Ben Upcroft	2017/1/1	None	Abstract This paper addresses the problem of detecting people and vehicles on a surface mine by presenting an architecture that combines the complementary strengths of deep convolutional networks (DCN) with cluster-based analysis. We highlight that using a DCN in a naïve black box approach results in a significantly high rate of errors due to the lack of mining-specific training data and the unique landscape in a mine site. In this work, we propose a background model that exploits the abundance of background-only images to  ...	0
Chris McCool, Tristan Perez, Ben Upcroft	2017/7	None	Abstract: We propose a novel approach for training deep convolutional neural networks (DCNNs) that allows us to tradeoff complexity and accuracy to learn lightweight models suitable for robotic platforms such as AgBot II (which performs automated weed management). Our approach consists of three stages, the first is to adapt a pre-trained model to the task at hand. This provides state-of-the-art performance but at the cost of high computational complexity resulting in a low frame rate of just 0.12 frames per second (fps).  ...	1
Adam Tow, Niko Sünderhauf, Sareh Shirazi, Michael Milford, Jürgen Leitner	2017/3/8	None	Abstract: We propose to learn tasks directly from visual demonstrations by learning to predict the outcome of human and robot actions on an environment. We enable a robot to physically perform a human demonstrated task without knowledge of the thought processes or actions of the human, only their visually observable state transitions. We evaluate our approach on two table-top, object manipulation tasks and demonstrate generalisation to previously unseen states. Our approach reduces the priors required to implement a robot task  ...	1
Inkyu Sa, Chris Lehnert, Andrew English, Chris McCool, Feras Dayoub, Ben Upcroft, Tristan Perez	2017/4	None	Abstract: This letter presents a three-dimensional (3-D) visual detection method for the challenging task of detecting peduncles of sweet peppers (Capsicum annuum) in the field. Cutting the peduncle cleanly is one of the most difficult stages of the harvesting process, where the peduncle is the part of the crop that attaches it to the main stem of the plant. Accurate peduncle detection in 3-D space is, therefore, a vital step in reliable autonomous harvesting of sweet peppers, as this can lead to precise cutting while avoiding damage to  ...	2
Feras Dayoub, Niko Sünderhauf, Peter Corke	2017/3/21	None	Abstract: We investigate different strategies for active learning with Bayesian deep neural networks. We focus our analysis on scenarios where new, unlabeled data is obtained episodically, such as commonly encountered in mobile robotics applications. An evaluation of different strategies for acquisition, updating, and final training on the CIFAR-10 dataset shows that incremental network updates with final training on the accumulated acquisition set are essential for best performance, while limiting the amount of required human  ...	0
David Hall, Feras Dayoub, Jason Kulk, Chris McCool	2017/2/4	None	Abstract: Weed scouting is an important part of modern integrated weed management but can be time consuming and sparse when performed manually. Automated weed scouting and weed destruction has typically been performed using classification systems able to classify a set group of species known a priori. This greatly limits deployability as classification systems must be retrained for any field with a different set of weed species present within them. In order to overcome this limitation, this paper works towards  ...	0
Matthew Dunbabin, Alistair Grinham	2017/1/1	None	Abstract Accurately quantifying total greenhouse gas emissions (eg, methane) from natural systems such as lakes, reservoirs, and wetlands requires the spatial and temporal measurement of both diffusive and ebullitive (bubbling) emissions. Ebullitive emissions exhibit high spatial and temporal variability and as such are difficult to measure. Traditional manual measurement techniques provide only limited localized assessment of methane flux, often introducing significant errors when extrapolated to the whole-of-system. This is  ...	2
Gavin Suddrey, Christopher Lehnert, Markus Eich, Frederic Maire, Jonathan Roberts	2017/1	None	Abstract: Natural language provides a convenient means of communicating information, and as such, is an ideal medium for enabling nonexpert users to teach robots novel tasks. However, in order to take advantage of natural language, a series of challenges must first be overcome. These challenges include the need to a) generalize learnt tasks to novel scenarios without retraining, b) resolve problems encountered during task execution, and c) derive implicit information from knowledge about the domain. To solve these challenges,  ...	1
Liao Wu, Ross Crawford, Jonathan Roberts	2017/4	None	Abstract: Continuum robots are increasingly used in minimally invasive surgeries. To date, the concentric tube mechanism and the cable-driven mechanism have been two prevalent mechanisms for constructing continuum robots. As these two mechanisms complement each other, it is worth exploring the possibility of combining them together. In this paper, we investigate the dexterity of three continuum robots combining both mechanisms. Indices based on the concept of orientability are introduced to analyze the distribution of the  ...	0
Anjali Jaiprakash, William B O’Callaghan, Sarah L Whitehouse, Ajay Pandey, Liao Wu, Jonathan Roberts, Ross W Crawford	2017/1/31	None	Purpose: To determine the perceptions of surgeons at both consultant and resident level to the difficulties of performing knee arthroscopy and to determine their willingness to adopt robotic technology. Methods: A questionnaire was designed to discern the attitude of orthopaedic consultants and residents to the technical challenges of performing knee arthroscopy and the possible role of robotically enhanced surgery. The questionnaire included 31 questions across five key domains. Results: Iatrogenic damage to articular  ...	0
Chuong V Nguyen, Michael Milford, Robert Mahony	2017/1/16	None	Abstract: Current self-driving car systems operate well in sunny weather but struggle in adverse conditions. One of the most commonly encountered adverse conditions involves water on the road caused by rain, sleet, melting snow or flooding. While some advances have been made in using conventional RGB camera and LIDAR technology for detecting water hazards, other sources of information such as polarization offer a promising and potentially superior approach to this problem in terms of performance and cost. In this  ...	0
Fahimeh Rezazadegan, Sareh Shirazi, Ben Upcroft, Michael Milford	2017	None	Abstract: Deep learning models have achieved state-of-the-art performance in recognizing human activities, but often rely on utilizing background cues present in typical computer vision datasets that predominantly have a stationary camera. If these models are to be employed by autonomous robots in real world environments, they must be adapted to perform independently of background cues and camera motion effects. To address these challenges, we propose a new method that firstly generates generic action region  ...	0
Zetao Chen, Adam Jacobson, Niko Sunderhauf, Ben Upcroft, Lingqiao Liu, Chunhua Shen, Ian Reid, Michael Milford	2017/1/18	None	Abstract: The success of deep learning techniques in the computer vision domain has triggered a range of initial investigations into their utility for visual place recognition, all using generic features from networks that were trained for other types of recognition tasks. In this paper, we train, at large scale, two CNN architectures for the specific place recognition task and employ a multi-scale feature encoding method to generate condition-and viewpoint-invariant features. To enable this training to occur, we have developed a massive Specific  ...	1
David Ball, Patrick Ross, Andrew English, Peter Milani, Daniel Richards, Andrew Bate, Ben Upcroft, Gordon Wyeth, Peter Corke	2017/4/19	None	Background To date, increasing productivity has largely been achieved through mechanization with increasingly large and complex machinery to optimize the human operator's time and crop genetics and technological advances such as automated steering with precision global navigation satellite systems (GNSS). However, these large machines cause significant soil compaction damage and present a single point of failure for timecritical farm operations. Many farming operations are also very time-consuming and repetitive.  ...	0
Aaron McFadyen, Marwen Jabeur, Peter Corke	2017/4	None	Abstract: This paper presents a new image-based visual servoing approach that simultaneously solves the feature correspondence and control problem. Using a finite-time optimal control framework, feature correspondence is implicitly solved for each new image during the control selection, alleviating the need for additional image processing and feature tracking. The proposed approach demonstrates mild robustness properties and leads to acceptable or improved image feature behavior and robot trajectories compared to  ...	1
Dorian Tsai, Donald G Dansereau, Thierry Peynot, Peter Corke	2017/4	None	Abstract: This paper proposes the first derivation, implementation, and experimental validation of light field image-based visual servoing. Light field image Jacobians are derived based on a compact light field feature representation that is close to the form measured directly by light field cameras. We also enhance feature detection and correspondence by enforcing light field geometry constraints, and directly estimate the image Jacobian without knowledge of point depth. The proposed approach is implemented over a standard visual  ...	0
Liao Wu, Ross Crawford, Jonathan Roberts	2017/4	None	Abstract: Continuum robots are increasingly used in minimally invasive surgeries. To date, the concentric tube mechanism and the cable-driven mechanism have been two prevalent mechanisms for constructing continuum robots. As these two mechanisms complement each other, it is worth exploring the possibility of combining them together. In this paper, we investigate the dexterity of three continuum robots combining both mechanisms. Indices based on the concept of orientability are introduced to analyze the distribution of the  ...	0
